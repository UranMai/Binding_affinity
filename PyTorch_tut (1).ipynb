{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_tut.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlv8qDy_ekfC",
        "colab_type": "text"
      },
      "source": [
        "# Installation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OxegKFcZLGA",
        "colab_type": "code",
        "outputId": "786d1db4-db73-4987-fe34-bccbd22c4bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CxAPEZyZZiu",
        "colab_type": "code",
        "outputId": "095579c5-4132-4978-f9ba-dce758159a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --verbose --no-cache-dir torch-scatter \n",
        "!pip install --verbose --no-cache-dir torch-sparse \n",
        "!pip install --verbose --no-cache-dir torch-cluster \n",
        "!pip install --verbose --no-cache-dir torch-spline-conv\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-zml6s9z5\n",
            "Created temporary directory: /tmp/pip-req-tracker-jgm409nh\n",
            "Created requirements tracker '/tmp/pip-req-tracker-jgm409nh'\n",
            "Created temporary directory: /tmp/pip-install-l3gt4hup\n",
            "1 location(s) to search for versions of torch-scatter:\n",
            "* https://pypi.org/simple/torch-scatter/\n",
            "Getting page https://pypi.org/simple/torch-scatter/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-scatter/ HTTP/1.1\" 200 1284\n",
            "Analyzing links from page https://pypi.org/simple/torch-scatter/\n",
            "  Found link https://files.pythonhosted.org/packages/29/96/566ac314e796d4b07209a3b88cc7a8d2e8582d55819e33f72e6c0e8d8216/torch_scatter-0.3.0.tar.gz#sha256=9e5e5a6efa4ef45f584e8611f83690d799370dd122b862646751ae112b685b50 (from https://pypi.org/simple/torch-scatter/), version: 0.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6a/b0/ecffacddf573c147c70c6e43ce05d24f007155ce3fb436959d3d2a24da46/torch_scatter-1.0.2.tar.gz#sha256=ccda794c25265b3450206b7fb0bf74f16a0b45f3f72d9547a42e44648a32faee (from https://pypi.org/simple/torch-scatter/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/09/07b106f3e74246f4ecf6517013a053b6dd7486c4f889d81f39adc662431f/torch_scatter-1.0.3.tar.gz#sha256=e626993194819ba65cdf89a52fbbb7780569d9e157bc63dbef13ead6b7a33930 (from https://pypi.org/simple/torch-scatter/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/2d/70/df2bc259d9606f00854ca43b6839f9047ec44900563435e0067584c93864/torch_scatter-1.0.4.tar.gz#sha256=ec004d687e47da9d5477407849d815629fc8b571ee87aeeebf6af8ed6f16defc (from https://pypi.org/simple/torch-scatter/), version: 1.0.4\n",
            "  Found link https://files.pythonhosted.org/packages/2f/97/c50a6aeaedc6924180c6f5810d2a7405ce11aa9b82ba4284badad549d665/torch_scatter-1.1.0.tar.gz#sha256=e534cc2ecb2f9d9b559b1513cd411737d26ea5585d1d65ff571fec55f42a49de (from https://pypi.org/simple/torch-scatter/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/91/5f/eb1d3ef3810cb1165859d40db4d9ee6d7f1dfef97d7e5c34010055f43d95/torch_scatter-1.1.1.tar.gz#sha256=9db7f2c0a5cddf6cfde633e33db7c2c94eaab163e9f8edb46460d6414cc97917 (from https://pypi.org/simple/torch-scatter/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/d4/83/67eeea00c2db1959e2ff95d8680dbd756977bfab254bda8658f09dc3bc11/torch_scatter-1.1.2.tar.gz#sha256=766c2476f5da5ffc25fa8e249ccf50f594031cdce3922abb23559e8e3b14337a (from https://pypi.org/simple/torch-scatter/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/07/c0/f7ac424496f4a3bcb31aa993fba29077a6d42fc2624c66e90b58a566a98e/torch_scatter-1.2.0.tar.gz#sha256=3a0259105d07d264c740eec8e4267260a5c144cf55472abd26022fff4fd73281 (from https://pypi.org/simple/torch-scatter/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/24/b7/680c3b392a4b55a0ebfb480aabb0d5c188e94bb21790104175c8cd614947/torch_scatter-1.3.0.tar.gz#sha256=bf7d561b8ef12b39a99f5797c90b989a0ce2c3ee4de74dff3b170f2d8566e1d4 (from https://pypi.org/simple/torch-scatter/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/35/d4/750403a8aa32cdb3d2d05849c6a10e4e0604de5e0cc94b81a0d0d69a75f3/torch_scatter-1.3.1.tar.gz#sha256=54cbad248350165ddc921ded3fe7a69be5d30c6536273a1a3282e375289f86ec (from https://pypi.org/simple/torch-scatter/), version: 1.3.1\n",
            "  Found link https://files.pythonhosted.org/packages/30/d9/1d5fd4d183dabd9e0a1f7008ecf83318432359f4cc27480e3f2212f44d9c/torch_scatter-1.3.2.tar.gz#sha256=890e8f9da2d57431912182960b71bf6c56397de42c2464907a6e9c583164bf06 (from https://pypi.org/simple/torch-scatter/), version: 1.3.2\n",
            "  Found link https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e (from https://pypi.org/simple/torch-scatter/), version: 1.4.0\n",
            "Given no hashes to check 12 links for project 'torch-scatter': discarding no candidates\n",
            "Using version 1.4.0 (newest of versions: 0.3.0, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.4.0)\n",
            "Collecting torch-scatter\n",
            "  Created temporary directory: /tmp/pip-unpack-z7og7bvv\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz HTTP/1.1\" 200 14692\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "  Added torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e to build tracker '/tmp/pip-req-tracker-jgm409nh'\n",
            "    Running setup.py (path:/tmp/pip-install-l3gt4hup/torch-scatter/setup.py) egg_info for package torch-scatter\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info\n",
            "    writing /tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-l3gt4hup/torch-scatter/pip-egg-info/torch_scatter.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-l3gt4hup/torch-scatter has version 1.4.0, which satisfies requirement torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e\n",
            "  Removed torch-scatter from https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz#sha256=5999ef256154e5a99445118c1a53f95cf0f95ef7b5cd8d3b256101125479cc2e from build tracker '/tmp/pip-req-tracker-jgm409nh'\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Created temporary directory: /tmp/pip-wheel-jxpjpg99\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-jxpjpg99\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-l3gt4hup/torch-scatter/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-l3gt4hup/torch-scatter/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-jxpjpg99 --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mean.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/sub.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/min.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/std.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/mul.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/add.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/max.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/logsumexp.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  copying torch_scatter/div.py -> build/lib.linux-x86_64-3.6/torch_scatter\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_multi_gpu.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_std.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_logsumexp.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_forward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_max_min.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_backward.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_broadcasting.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/ext.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  copying torch_scatter/utils/gen.py -> build/lib.linux-x86_64-3.6/torch_scatter/utils\n",
            "  creating build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-3.6/torch_scatter/composite\n",
            "  running build_ext\n",
            "  building 'torch_scatter.scatter_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/scatter.cpp -o build/temp.linux-x86_64-3.6/cpu/scatter.o -Wno-unused-variable -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/scatter.o -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_scatter.scatter_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter.cpp -o build/temp.linux-x86_64-3.6/cuda/scatter.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/scatter_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/scatter.o build/temp.linux-x86_64-3.6/cuda/scatter_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mean.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/ext.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/utils/gen.py -> build/bdist.linux-x86_64/wheel/torch_scatter/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/composite/__init__.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/composite/softmax.py -> build/bdist.linux-x86_64/wheel/torch_scatter/composite\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/sub.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/min.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/std.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/mul.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/add.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/max.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/logsumexp.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  copying build/lib.linux-x86_64-3.6/torch_scatter/div.py -> build/bdist.linux-x86_64/wheel/torch_scatter\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_multi_gpu.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_std.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_logsumexp.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_forward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_max_min.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_backward.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_broadcasting.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_scatter.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
            "  writing top-level names to torch_scatter.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
            "  Copying torch_scatter.egg-info to build/bdist.linux-x86_64/wheel/torch_scatter-1.4.0-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_scatter-1.4.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-jxpjpg99/torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_backward.py'\n",
            "  adding 'test/test_broadcasting.py'\n",
            "  adding 'test/test_forward.py'\n",
            "  adding 'test/test_logsumexp.py'\n",
            "  adding 'test/test_max_min.py'\n",
            "  adding 'test/test_multi_gpu.py'\n",
            "  adding 'test/test_std.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_scatter/__init__.py'\n",
            "  adding 'torch_scatter/add.py'\n",
            "  adding 'torch_scatter/div.py'\n",
            "  adding 'torch_scatter/logsumexp.py'\n",
            "  adding 'torch_scatter/max.py'\n",
            "  adding 'torch_scatter/mean.py'\n",
            "  adding 'torch_scatter/min.py'\n",
            "  adding 'torch_scatter/mul.py'\n",
            "  adding 'torch_scatter/scatter_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/scatter_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_scatter/std.py'\n",
            "  adding 'torch_scatter/sub.py'\n",
            "  adding 'torch_scatter/composite/__init__.py'\n",
            "  adding 'torch_scatter/composite/softmax.py'\n",
            "  adding 'torch_scatter/utils/__init__.py'\n",
            "  adding 'torch_scatter/utils/ext.py'\n",
            "  adding 'torch_scatter/utils/gen.py'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/LICENSE'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/METADATA'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/WHEEL'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/top_level.txt'\n",
            "  adding 'torch_scatter-1.4.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=3170367 sha256=8b35cfbe1ab121e87ec0a29ccc6759b81581e783182ccf4d8d48351b3fd9a011\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zml6s9z5/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "  Removing source in /tmp/pip-install-l3gt4hup/torch-scatter\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "\n",
            "Successfully installed torch-scatter-1.4.0\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-jgm409nh'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-lg1f580q\n",
            "Created temporary directory: /tmp/pip-req-tracker-vb0jkffe\n",
            "Created requirements tracker '/tmp/pip-req-tracker-vb0jkffe'\n",
            "Created temporary directory: /tmp/pip-install-wjkw44wl\n",
            "1 location(s) to search for versions of torch-sparse:\n",
            "* https://pypi.org/simple/torch-sparse/\n",
            "Getting page https://pypi.org/simple/torch-sparse/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-sparse/ HTTP/1.1\" 200 1096\n",
            "Analyzing links from page https://pypi.org/simple/torch-sparse/\n",
            "  Found link https://files.pythonhosted.org/packages/21/a6/af5865f7bc2dc45ea789ebb35bdf5d84c05e140d7d2ec7e5823d24db176f/torch_sparse-0.1.0.tar.gz#sha256=d774c4b05a96bf09e3c3becd2f48c65ed66b03195a2cfc4992ef57c9a8c6b399 (from https://pypi.org/simple/torch-sparse/), version: 0.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/02/4f/89bcb156022a3960c4db852915c64ea78b4e993e0f8d7a83e60e6819fc11/torch_sparse-0.2.0.tar.gz#sha256=578fdc3522b06c948d43fbc360d0dcde8a89d9a2496ac468592bf3493baedd33 (from https://pypi.org/simple/torch-sparse/), version: 0.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/8f/41/98db80cc9d9345c76445393661ce4dd3e08fc46fb17028e7706612063e4d/torch_sparse-0.2.1.tar.gz#sha256=01346234f0e76103304f8aa1099f22c0904d2fff8b36c5ec0230335149f526bc (from https://pypi.org/simple/torch-sparse/), version: 0.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/73/5b/5b7b6c66148afaa5e2ed8a3e18e109361957d28e67032d92cb282d173f32/torch_sparse-0.2.2.tar.gz#sha256=11e87c0214a4491168f15726ddda6c771b5f34be728f3edbb4add203e46d924d (from https://pypi.org/simple/torch-sparse/), version: 0.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/43/2a/bb2ead5b33c6932937c6c74199ebecd72bd4b3ab224842a50366e5b2af4a/torch_sparse-0.2.3.tar.gz#sha256=47b3f85b0c243d0c98798db722b0f066830f6b8ff9d298a6e2aed0662598e356 (from https://pypi.org/simple/torch-sparse/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/73/72/e374662f6f47d9ac0e082a6d5c18d14e15c52863e89c6bc6957a0d2ed026/torch_sparse-0.2.4.tar.gz#sha256=5cae8b40a5d11b8917e0f4b95034b5842b052f42a089ce59f8c02f2cff00ca55 (from https://pypi.org/simple/torch-sparse/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/b0/0a/2ff678e0d04e524dd2cf990a6202ced8c0ffe3fe6b08e02f25cc9fd27da0/torch_sparse-0.4.0.tar.gz#sha256=bf217539b4f714a1d6fac4d39ace3ad8033871717f44f8f365a2746056b9d805 (from https://pypi.org/simple/torch-sparse/), version: 0.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/c7/3e/aa5449787910283d846a7c739899ccf8c53c914f8a7aee7bc500a32dc091/torch_sparse-0.4.1.tar.gz#sha256=4831fe4b78b86d4dff948d50fec042ef99b98e850495b400189456380ec397d4 (from https://pypi.org/simple/torch-sparse/), version: 0.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/7d/c5/1f73917168aa9816f41e0696f266fa07d0ebfe8d25c3e63a0f08440534b9/torch_sparse-0.4.2.tar.gz#sha256=a652feb1b945995fb863dcbfdaa01de9096d5ed7230380ebf6d262e649eb4123 (from https://pypi.org/simple/torch-sparse/), version: 0.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f (from https://pypi.org/simple/torch-sparse/), version: 0.4.3\n",
            "Given no hashes to check 10 links for project 'torch-sparse': discarding no candidates\n",
            "Using version 0.4.3 (newest of versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.4.0, 0.4.1, 0.4.2, 0.4.3)\n",
            "Collecting torch-sparse\n",
            "  Created temporary directory: /tmp/pip-unpack-7aqxf1us\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz HTTP/1.1\" 200 11018\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "  Added torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f to build tracker '/tmp/pip-req-tracker-vb0jkffe'\n",
            "    Running setup.py (path:/tmp/pip-install-wjkw44wl/torch-sparse/setup.py) egg_info for package torch-sparse\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info\n",
            "    writing /tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-wjkw44wl/torch-sparse/pip-egg-info/torch_sparse.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-wjkw44wl/torch-sparse has version 0.4.3, which satisfies requirement torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f\n",
            "  Removed torch-sparse from https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz#sha256=87b63cb21f091b450271e75d42280c9ef165d61e6ae6dcb983ad2caedfd6eb0f from build tracker '/tmp/pip-req-tracker-vb0jkffe'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Created temporary directory: /tmp/pip-wheel-ctqlhwch\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-ctqlhwch\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-wjkw44wl/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-wjkw44wl/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-ctqlhwch --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_coalesce.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_transpose.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm_spmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_eye.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_convert.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_spspmm.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/unique.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  copying torch_sparse/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse/utils\n",
            "  running build_ext\n",
            "  building 'torch_sparse.spspmm_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/spspmm.cpp -o build/temp.linux-x86_64-3.6/cpu/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/spspmm.o -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_sparse.spspmm_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm.cpp -o build/temp.linux-x86_64-3.6/cuda/spspmm.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/spspmm_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=spspmm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/spspmm.o build/temp.linux-x86_64-3.6/cuda/spspmm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -lcusparse -l cusparse\n",
            "  building 'torch_sparse.unique_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique.cpp -o build/temp.linux-x86_64-3.6/cuda/unique.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/unique_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=unique_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/unique.o build/temp.linux-x86_64-3.6/cuda/unique_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/eye.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/unique.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/__init__.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/coalesce.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/transpose.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/convert.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  copying build/lib.linux-x86_64-3.6/torch_sparse/spmm.py -> build/bdist.linux-x86_64/wheel/torch_sparse\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_coalesce.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_transpose.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm_spmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_eye.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_convert.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_spspmm.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_sparse.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_sparse.egg-info/requires.txt\n",
            "  writing top-level names to torch_sparse.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
            "  Copying torch_sparse.egg-info to build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_sparse-0.4.3.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-ctqlhwch/torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_coalesce.py'\n",
            "  adding 'test/test_convert.py'\n",
            "  adding 'test/test_eye.py'\n",
            "  adding 'test/test_spmm.py'\n",
            "  adding 'test/test_spspmm.py'\n",
            "  adding 'test/test_spspmm_spmm.py'\n",
            "  adding 'test/test_transpose.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_sparse/__init__.py'\n",
            "  adding 'torch_sparse/coalesce.py'\n",
            "  adding 'torch_sparse/convert.py'\n",
            "  adding 'torch_sparse/eye.py'\n",
            "  adding 'torch_sparse/spmm.py'\n",
            "  adding 'torch_sparse/spspmm.py'\n",
            "  adding 'torch_sparse/spspmm_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/spspmm_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/transpose.py'\n",
            "  adding 'torch_sparse/unique_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_sparse/utils/__init__.py'\n",
            "  adding 'torch_sparse/utils/unique.py'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/LICENSE'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/METADATA'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/WHEEL'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/top_level.txt'\n",
            "  adding 'torch_sparse-0.4.3.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3966670 sha256=057f23b1cab5467382f844b54ee78cca7bf8dab73825b4d682fae6ccfdf085ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lg1f580q/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "  Removing source in /tmp/pip-install-wjkw44wl/torch-sparse\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "\n",
            "Successfully installed torch-sparse-0.4.3\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-vb0jkffe'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-i7o2eadx\n",
            "Created temporary directory: /tmp/pip-req-tracker-1hucwju9\n",
            "Created requirements tracker '/tmp/pip-req-tracker-1hucwju9'\n",
            "Created temporary directory: /tmp/pip-install-o29yefrp\n",
            "1 location(s) to search for versions of torch-cluster:\n",
            "* https://pypi.org/simple/torch-cluster/\n",
            "Getting page https://pypi.org/simple/torch-cluster/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-cluster/ HTTP/1.1\" 200 2174\n",
            "Analyzing links from page https://pypi.org/simple/torch-cluster/\n",
            "  Found link https://files.pythonhosted.org/packages/58/77/1ddc3390129653d1e0e1e0c8063d47a2f40abc888d95b4a2fba774e215df/torch_cluster-0.1.1.tar.gz#sha256=f4f64eabc4c380bff9863d3ce9b93b0a65c7ea6f797f9ee053dc74d7d92ea928 (from https://pypi.org/simple/torch-cluster/), version: 0.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/ac/92/c583aabacb052afed67db146662c23625ad861a74140e338996816a879f4/torch_cluster-0.2.3.tar.gz#sha256=43d9840078f962abfced55043d8320f80c7f91aa7f54398b9ad631ee577bbfb1 (from https://pypi.org/simple/torch-cluster/), version: 0.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/6e/9b/493def262b256290ad6913c9f36b774af6f52d9d46d3fee31b77b3803eb0/torch_cluster-0.2.4.tar.gz#sha256=f421986d71a644b72c69551f09df31eb8657203d59d639aac33192192ed675b5 (from https://pypi.org/simple/torch-cluster/), version: 0.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/8a/2c/ddf6e6fc9c4af6c37a20996100cf6a6427accd7939470bc99071d3487753/torch_cluster-1.0.1.tar.gz#sha256=04cf3ad486eff6cc6069e3d1c18a2acd7662169f36d02a13f3a7adaabfc06b91 (from https://pypi.org/simple/torch-cluster/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/87/9d/e488a5186684632e3e0f14eaec125936cf25a3a24552afd26e7bb426d2ee/torch_cluster-1.0.3.tar.gz#sha256=795264f9e9f36eb44aeb28716d68ea93cd6dc7f75c8e05e0d16eb0597ffcd1a6 (from https://pypi.org/simple/torch-cluster/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/7b/95/bca3179ce501792bf268d37f18cc82577c289fa093bfdcfc26e375019da5/torch_cluster-1.1.1.tar.gz#sha256=e919f64153fd97efe958a509a0a558a31bf5f2dbe2deeff09d300e33d3994b14 (from https://pypi.org/simple/torch-cluster/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/36/b0/25ca8b811059e001f1e3285ac3036b6969fb21350e411c6881ba2b9be3c3/torch_cluster-1.1.2.tar.gz#sha256=082c4e71079cd1bed89da4178b3391361fa6aac5ae2edb783c08fed3da5b93c4 (from https://pypi.org/simple/torch-cluster/), version: 1.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/e2/4f/5205f832d3eef871fe71564aa9fb8504a65be5e95be09800e125e224e634/torch_cluster-1.1.3.tar.gz#sha256=d5c80159f91e329bcc95b316a29ecf466257598680b3b5fb2ea137a585037c78 (from https://pypi.org/simple/torch-cluster/), version: 1.1.3\n",
            "  Found link https://files.pythonhosted.org/packages/d0/e1/495ecc73f1e5534ecbedf1a301557d6c9fc93417467e5107fd9ac54fcbfa/torch_cluster-1.1.4.tar.gz#sha256=a298694afe91f146be3921b8c9da06051958b7598c6e69a9af5833a1af56e7f3 (from https://pypi.org/simple/torch-cluster/), version: 1.1.4\n",
            "  Found link https://files.pythonhosted.org/packages/a6/b3/de9c051d1df504d78542d178231f2ae7d08a411c9ca59219028742886947/torch_cluster-1.1.5.tar.gz#sha256=b67d6c89b71e4146dcfa078cc6a201a1647d888441a9f278b30770f91c7978a1 (from https://pypi.org/simple/torch-cluster/), version: 1.1.5\n",
            "  Found link https://files.pythonhosted.org/packages/96/de/9506fa869cf52edc58c2517b41c0ec1c7678c05b95aff000a509e4238765/torch_cluster-1.2.1.tar.gz#sha256=371b438113bcb7cab1b6931740e9194972f0f7349e1d033437a4196d7d693130 (from https://pypi.org/simple/torch-cluster/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/b7/05b9ce9afc76f5709efe04d6344fbed09ea217f916f94e63f2fe9659eb62/torch_cluster-1.2.2.tar.gz#sha256=a1e39e16a7ade806a852117fe16fe2b505fd4bc43bc4207f48fecb0f6b2e1f64 (from https://pypi.org/simple/torch-cluster/), version: 1.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/67/19/a0b1e3a7633ced39d9977ce0b98a1b3e343f0772f4090b0a2d421ac5b56d/torch_cluster-1.2.3.tar.gz#sha256=f8a6b5f47bf6a2a396301d0f4ec0733a650f7a5ae84b08b8625408b8979747ea (from https://pypi.org/simple/torch-cluster/), version: 1.2.3\n",
            "  Found link https://files.pythonhosted.org/packages/32/c8/9b3af10be647326dd807bb2fe7ced8ae4c3fd74178dba884621749afc4d7/torch_cluster-1.2.4.tar.gz#sha256=4e5f8c15b28329b269adecadd64917cb5373c6438a5fdf463f633bd4e73c4ae6 (from https://pypi.org/simple/torch-cluster/), version: 1.2.4\n",
            "  Found link https://files.pythonhosted.org/packages/93/f9/89319a7344e5bcda090fb3996c4271b1fda238ad90401a315c9af1ce4137/torch_cluster-1.3.0.tar.gz#sha256=7b0e1b7061bf8c2754d63a66159f47757ce28b072bc37921fbcc59974eb2d342 (from https://pypi.org/simple/torch-cluster/), version: 1.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/6b/3b/a34740494a1b25cb2ef4ed09e5d5ef6bc75be884f6b25bd93a7acdf03134/torch_cluster-1.4.0.tar.gz#sha256=c256d61f20193b104a2f4c610b4ad95fa3cbaeb72b2ae9bf3d254cb3d573e945 (from https://pypi.org/simple/torch-cluster/), version: 1.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/2f/0c/77453228c248e8071d185940ecb3dd9eca3cac180767bde75b2bc05c0c65/torch_cluster-1.4.1.tar.gz#sha256=e7a900d54cb2dc241c84b1da382f358399880c61290f7be72babf98500496494 (from https://pypi.org/simple/torch-cluster/), version: 1.4.1\n",
            "  Found link https://files.pythonhosted.org/packages/33/38/60ad2fcb735123429b3e0b165a19c80c6273d679b01d6550782abcb314e2/torch_cluster-1.4.2.tar.gz#sha256=ed437ec01f431d0f36398cc321524aac27870cc09e7a5a869726af9c15ac354a (from https://pypi.org/simple/torch-cluster/), version: 1.4.2\n",
            "  Found link https://files.pythonhosted.org/packages/7e/30/b315f136648801433ce6b2724fe3bfaae3c0f8a13282aa58d38ad2a8a3db/torch_cluster-1.4.3a1.tar.gz#sha256=680e47ee41a0cec223c179ce3ea2174de48ac6a277eced453ccadf4bdd2f51c9 (from https://pypi.org/simple/torch-cluster/), version: 1.4.3a1\n",
            "  Found link https://files.pythonhosted.org/packages/49/0d/f7151fb6aad5c9b0e032e46c0678e0404870de4add35b0723fc2a5c4af35/torch_cluster-1.4.3.tar.gz#sha256=340eaf9e31a7a0618f2c3d61c480e1d74466c930827f10fee86d11d8c5b85cba (from https://pypi.org/simple/torch-cluster/), version: 1.4.3\n",
            "  Found link https://files.pythonhosted.org/packages/bd/5f/01c5799cd1f81f9956f03a0e1d9a861e020a598dd411d9bd3c3c1dd5b8a4/torch_cluster-1.4.4.tar.gz#sha256=7907f3f270116cb299bdd4f88de497a85b3b34cf127910ffe0a6131e16620123 (from https://pypi.org/simple/torch-cluster/), version: 1.4.4\n",
            "  Found link https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 (from https://pypi.org/simple/torch-cluster/), version: 1.4.5\n",
            "Given no hashes to check 21 links for project 'torch-cluster': discarding no candidates\n",
            "Using version 1.4.5 (newest of versions: 0.1.1, 0.2.3, 0.2.4, 1.0.1, 1.0.3, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.3.0, 1.4.0, 1.4.1, 1.4.2, 1.4.3, 1.4.4, 1.4.5)\n",
            "Collecting torch-cluster\n",
            "  Created temporary directory: /tmp/pip-unpack-9eknctev\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz HTTP/1.1\" 200 18790\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "  Added torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 to build tracker '/tmp/pip-req-tracker-1hucwju9'\n",
            "    Running setup.py (path:/tmp/pip-install-o29yefrp/torch-cluster/setup.py) egg_info for package torch-cluster\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info\n",
            "    writing /tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-o29yefrp/torch-cluster/pip-egg-info/torch_cluster.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-o29yefrp/torch-cluster has version 1.4.5, which satisfies requirement torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257\n",
            "  Removed torch-cluster from https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz#sha256=cf5b9363d82173bb26bb966ba93712c3262765a3a4d25c003479732a9260c257 from build tracker '/tmp/pip-req-tracker-1hucwju9'\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.5)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Created temporary directory: /tmp/pip-wheel-xicd6b1o\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-xicd6b1o\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-o29yefrp/torch-cluster/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-o29yefrp/torch-cluster/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-xicd6b1o --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/grid.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/nearest.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/fps.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/knn.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/__init__.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/radius.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/sampler.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/rw.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  copying torch_cluster/graclus.py -> build/lib.linux-x86_64-3.6/torch_cluster\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_fps.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_grid.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_radius.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_nearest.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_knn.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_graclus.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_sampler.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_rw.py -> build/lib.linux-x86_64-3.6/test\n",
            "  running build_ext\n",
            "  building 'torch_cluster.graclus_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/graclus.cpp -o build/temp.linux-x86_64-3.6/cpu/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/graclus.o -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/grid.cpp -o build/temp.linux-x86_64-3.6/cpu/grid.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/grid.o -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/fps.cpp -o build/temp.linux-x86_64-3.6/cpu/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/fps.o -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/rw.cpp -o build/temp.linux-x86_64-3.6/cpu/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/rw.o -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.sampler_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/sampler.cpp -o build/temp.linux-x86_64-3.6/cpu/sampler.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=sampler_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/sampler.o -o build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.graclus_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus.cpp -o build/temp.linux-x86_64-3.6/cuda/graclus.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/graclus_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=graclus_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/graclus.o build/temp.linux-x86_64-3.6/cuda/graclus_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.grid_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid.cpp -o build/temp.linux-x86_64-3.6/cuda/grid.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/grid_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=grid_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/grid.o build/temp.linux-x86_64-3.6/cuda/grid_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.fps_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps.cpp -o build/temp.linux-x86_64-3.6/cuda/fps.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/fps_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fps_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/fps.o build/temp.linux-x86_64-3.6/cuda/fps_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.nearest_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest.cpp -o build/temp.linux-x86_64-3.6/cuda/nearest.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/nearest_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nearest_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/nearest.o build/temp.linux-x86_64-3.6/cuda/nearest_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.knn_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn.cpp -o build/temp.linux-x86_64-3.6/cuda/knn.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/knn_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=knn_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/knn.o build/temp.linux-x86_64-3.6/cuda/knn_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.radius_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius.cpp -o build/temp.linux-x86_64-3.6/cuda/radius.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/radius_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=radius_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/radius.o build/temp.linux-x86_64-3.6/cuda/radius_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_cluster.rw_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw.cpp -o build/temp.linux-x86_64-3.6/cuda/rw.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/rw_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=rw_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/rw.o build/temp.linux-x86_64-3.6/cuda/rw_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/__init__.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/radius.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/sampler.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/rw.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  copying build/lib.linux-x86_64-3.6/torch_cluster/graclus.py -> build/bdist.linux-x86_64/wheel/torch_cluster\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_fps.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_grid.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_radius.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_nearest.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_knn.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_graclus.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_sampler.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_rw.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_cluster.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_cluster.egg-info/dependency_links.txt\n",
            "  writing requirements to torch_cluster.egg-info/requires.txt\n",
            "  writing top-level names to torch_cluster.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_cluster.egg-info/SOURCES.txt'\n",
            "  Copying torch_cluster.egg-info to build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_cluster-1.4.5.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-xicd6b1o/torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_fps.py'\n",
            "  adding 'test/test_graclus.py'\n",
            "  adding 'test/test_grid.py'\n",
            "  adding 'test/test_knn.py'\n",
            "  adding 'test/test_nearest.py'\n",
            "  adding 'test/test_radius.py'\n",
            "  adding 'test/test_rw.py'\n",
            "  adding 'test/test_sampler.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_cluster/__init__.py'\n",
            "  adding 'torch_cluster/fps.py'\n",
            "  adding 'torch_cluster/fps_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/fps_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus.py'\n",
            "  adding 'torch_cluster/graclus_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/graclus_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid.py'\n",
            "  adding 'torch_cluster/grid_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/grid_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/knn.py'\n",
            "  adding 'torch_cluster/knn_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/nearest.py'\n",
            "  adding 'torch_cluster/nearest_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/radius.py'\n",
            "  adding 'torch_cluster/radius_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw.py'\n",
            "  adding 'torch_cluster/rw_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/rw_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster/sampler.py'\n",
            "  adding 'torch_cluster/sampler_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/LICENSE'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/METADATA'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/WHEEL'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/top_level.txt'\n",
            "  adding 'torch_cluster-1.4.5.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16231814 sha256=e6c57bc6903db7add77d12bfe0529d55794f79859a5ad082dbd90ee64a5cc7e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7o2eadx/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "  Removing source in /tmp/pip-install-o29yefrp/torch-cluster\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "\n",
            "Successfully installed torch-cluster-1.4.5\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-1hucwju9'\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-lt4rymro\n",
            "Created temporary directory: /tmp/pip-req-tracker-lczie7mh\n",
            "Created requirements tracker '/tmp/pip-req-tracker-lczie7mh'\n",
            "Created temporary directory: /tmp/pip-install-yzt709je\n",
            "1 location(s) to search for versions of torch-spline-conv:\n",
            "* https://pypi.org/simple/torch-spline-conv/\n",
            "Getting page https://pypi.org/simple/torch-spline-conv/\n",
            "Found index url https://pypi.org/simple\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-spline-conv/ HTTP/1.1\" 200 1023\n",
            "Analyzing links from page https://pypi.org/simple/torch-spline-conv/\n",
            "  Found link https://files.pythonhosted.org/packages/43/48/02fd06eca47d38efc031b34875c2e7453faab7bde7c02b2669957d230693/torch_spline_conv-0.1.0.tar.gz#sha256=b1d7bceecffb4bc394d9f5df57b56fbff95867aeb778588a054e95a6ba5cd610 (from https://pypi.org/simple/torch-spline-conv/), version: 0.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/99/a6/19a54aaaf507960814af5b6ec3d6916497d54a9345d0b64a98764465fddc/torch_spline_conv-1.0.0.tar.gz#sha256=72950ae9cc15dd00d0977ffca115af0e59c10f1dbac33dd800307fef2b5808c3 (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/4a/e9/973d572b69f8fef3b08d86f77312a75ab4c00ffe8d3582ae09b433b34b8a/torch_spline_conv-1.0.1.tar.gz#sha256=6be33fab8402950b2ddc1dec950d0b5d4c6f183bcf53bca2534a03eb4fd5801b (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/bc/ff/4e834a74fd180f87f6f9aedcfd876cca4c6fa706afa31e9541838f6958d1/torch_spline_conv-1.0.3.tar.gz#sha256=a0be3bc9847458ca92146c2da754dbd2f910be426414757256416e507240da88 (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.3\n",
            "  Found link https://files.pythonhosted.org/packages/1b/d2/98328ef2395b70b9795ddbd091398e49e918f8892d1ea8dad869550b684b/torch_spline_conv-1.0.4.tar.gz#sha256=26e2bb0832d45d185f2e7b38569e64e7f70af8ca2a8b05663972f261ba76a978 (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.4\n",
            "  Found link https://files.pythonhosted.org/packages/92/86/f086f96e09654106ad527f4b03ac6188c1299a9fe555fc39c663b155a05a/torch_spline_conv-1.0.5.tar.gz#sha256=fffa87c94703e4c43a46bd8ec149cd6c125586ebd1f3c04fec48d1f6b60a4f3c (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.5\n",
            "  Found link https://files.pythonhosted.org/packages/9a/6d/b34721af4bb907814a41a1e0e5e426c97aee644efef6877ed112bfb3d81c/torch_spline_conv-1.0.6.tar.gz#sha256=a8bd72bac7dc078ddfbf22789c5fcdf159901494c626344d67ad203e7f8c9b1e (from https://pypi.org/simple/torch-spline-conv/), version: 1.0.6\n",
            "  Found link https://files.pythonhosted.org/packages/3c/dd/daa9d0b7b2ede913e573876ae286a58ec296678858f2814ff6d6789b234f/torch_spline_conv-1.1.0.tar.gz#sha256=e6029526205d1f7cb535389bebd81decf0649a20ea6a67688c02bd335a7f9339 (from https://pypi.org/simple/torch-spline-conv/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz#sha256=622e2f3763e41044f6364ff7a4c6a417cb73c7e6a6edec763abd14847863ebd2 (from https://pypi.org/simple/torch-spline-conv/), version: 1.1.1\n",
            "Given no hashes to check 9 links for project 'torch-spline-conv': discarding no candidates\n",
            "Using version 1.1.1 (newest of versions: 0.1.0, 1.0.0, 1.0.1, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.1.0, 1.1.1)\n",
            "Collecting torch-spline-conv\n",
            "  Created temporary directory: /tmp/pip-unpack-hgw2v_r4\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz HTTP/1.1\" 200 13199\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz\n",
            "  Added torch-spline-conv from https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz#sha256=622e2f3763e41044f6364ff7a4c6a417cb73c7e6a6edec763abd14847863ebd2 to build tracker '/tmp/pip-req-tracker-lczie7mh'\n",
            "    Running setup.py (path:/tmp/pip-install-yzt709je/torch-spline-conv/setup.py) egg_info for package torch-spline-conv\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info\n",
            "    writing /tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    writing manifest file '/tmp/pip-install-yzt709je/torch-spline-conv/pip-egg-info/torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-yzt709je/torch-spline-conv has version 1.1.1, which satisfies requirement torch-spline-conv from https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz#sha256=622e2f3763e41044f6364ff7a4c6a417cb73c7e6a6edec763abd14847863ebd2\n",
            "  Removed torch-spline-conv from https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz#sha256=622e2f3763e41044f6364ff7a4c6a417cb73c7e6a6edec763abd14847863ebd2 from build tracker '/tmp/pip-req-tracker-lczie7mh'\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Created temporary directory: /tmp/pip-wheel-yuj_zgbc\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-yuj_zgbc\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-yzt709je/torch-spline-conv/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-yzt709je/torch-spline-conv/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-yuj_zgbc --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.6\n",
            "  creating build/lib.linux-x86_64-3.6/torch_spline_conv\n",
            "  copying torch_spline_conv/__init__.py -> build/lib.linux-x86_64-3.6/torch_spline_conv\n",
            "  copying torch_spline_conv/weighting.py -> build/lib.linux-x86_64-3.6/torch_spline_conv\n",
            "  copying torch_spline_conv/basis.py -> build/lib.linux-x86_64-3.6/torch_spline_conv\n",
            "  copying torch_spline_conv/conv.py -> build/lib.linux-x86_64-3.6/torch_spline_conv\n",
            "  creating build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_conv.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_basis.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/__init__.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/test_weighting.py -> build/lib.linux-x86_64-3.6/test\n",
            "  copying test/utils.py -> build/lib.linux-x86_64-3.6/test\n",
            "  creating build/lib.linux-x86_64-3.6/torch_spline_conv/utils\n",
            "  copying torch_spline_conv/utils/__init__.py -> build/lib.linux-x86_64-3.6/torch_spline_conv/utils\n",
            "  copying torch_spline_conv/utils/degree.py -> build/lib.linux-x86_64-3.6/torch_spline_conv/utils\n",
            "  running build_ext\n",
            "  building 'torch_spline_conv.basis_cpu' extension\n",
            "  creating build/temp.linux-x86_64-3.6\n",
            "  creating build/temp.linux-x86_64-3.6/cpu\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/basis.cpp -o build/temp.linux-x86_64-3.6/cpu/basis.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=basis_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/basis.o -o build/lib.linux-x86_64-3.6/torch_spline_conv/basis_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_spline_conv.weighting_cpu' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c cpu/weighting.cpp -o build/temp.linux-x86_64-3.6/cpu/weighting.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=weighting_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cpu/weighting.o -o build/lib.linux-x86_64-3.6/torch_spline_conv/weighting_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_spline_conv.basis_cuda' extension\n",
            "  creating build/temp.linux-x86_64-3.6/cuda\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/basis.cpp -o build/temp.linux-x86_64-3.6/cuda/basis.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=basis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/basis_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/basis_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=basis_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/basis.o build/temp.linux-x86_64-3.6/cuda/basis_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_spline_conv/basis_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  building 'torch_spline_conv.weighting_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/weighting.cpp -o build/temp.linux-x86_64-3.6/cuda/weighting.o -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=weighting_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c cuda/weighting_kernel.cu -o build/temp.linux-x86_64-3.6/cuda/weighting_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=weighting_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/cuda/weighting.o build/temp.linux-x86_64-3.6/cuda/weighting_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/torch_spline_conv/weighting_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/weighting_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/weighting_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_spline_conv/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/utils/__init__.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/utils/degree.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv/utils\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/__init__.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/weighting.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/basis.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/basis_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/basis_cpu.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  copying build/lib.linux-x86_64-3.6/torch_spline_conv/conv.py -> build/bdist.linux-x86_64/wheel/torch_spline_conv\n",
            "  creating build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_conv.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_basis.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/__init__.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/test_weighting.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  copying build/lib.linux-x86_64-3.6/test/utils.py -> build/bdist.linux-x86_64/wheel/test\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing torch_spline_conv.egg-info/PKG-INFO\n",
            "  writing dependency_links to torch_spline_conv.egg-info/dependency_links.txt\n",
            "  writing top-level names to torch_spline_conv.egg-info/top_level.txt\n",
            "  reading manifest file 'torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  writing manifest file 'torch_spline_conv.egg-info/SOURCES.txt'\n",
            "  Copying torch_spline_conv.egg-info to build/bdist.linux-x86_64/wheel/torch_spline_conv-1.1.1-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/torch_spline_conv-1.1.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-yuj_zgbc/torch_spline_conv-1.1.1-cp36-cp36m-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'test/__init__.py'\n",
            "  adding 'test/test_basis.py'\n",
            "  adding 'test/test_conv.py'\n",
            "  adding 'test/test_weighting.py'\n",
            "  adding 'test/utils.py'\n",
            "  adding 'torch_spline_conv/__init__.py'\n",
            "  adding 'torch_spline_conv/basis.py'\n",
            "  adding 'torch_spline_conv/basis_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_spline_conv/basis_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_spline_conv/conv.py'\n",
            "  adding 'torch_spline_conv/weighting.py'\n",
            "  adding 'torch_spline_conv/weighting_cpu.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_spline_conv/weighting_cuda.cpython-36m-x86_64-linux-gnu.so'\n",
            "  adding 'torch_spline_conv/utils/__init__.py'\n",
            "  adding 'torch_spline_conv/utils/degree.py'\n",
            "  adding 'torch_spline_conv-1.1.1.dist-info/LICENSE'\n",
            "  adding 'torch_spline_conv-1.1.1.dist-info/METADATA'\n",
            "  adding 'torch_spline_conv-1.1.1.dist-info/WHEEL'\n",
            "  adding 'torch_spline_conv-1.1.1.dist-info/top_level.txt'\n",
            "  adding 'torch_spline_conv-1.1.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.1.1-cp36-cp36m-linux_x86_64.whl size=5469752 sha256=32e47d2f29387d8da75aa8ce7ff2a39c8bd3ab3ca7b3f61dd0cf809226465b33\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lt4rymro/wheels/63/cf/c7/3439a98ba262c5d99b91a9c11aaeced67f583febab5a4b1566\n",
            "  Removing source in /tmp/pip-install-yzt709je/torch-spline-conv\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "\n",
            "Successfully installed torch-spline-conv-1.1.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-lczie7mh'\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\u001b[K     || 133kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     || 348kB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.6)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     || 51kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=ca9372acce9725fd10f357342bc0b3dfe245c2121b6804b5d4bde57b6dbe641d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=429a3e60f25c229b92cea93999d33b59acbae880dcaf65d3fc91d3e107305ea0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk27XIUsbmON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_geometric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzNBzOyebpk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn import Sequential as Seq, Linear, ReLU\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FLitsNseFAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.data import Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzDRnoqpb0bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import csv\n",
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKLkTGKxeUfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOfE5yLYC8w1",
        "colab_type": "code",
        "outputId": "f42919b3-8f3e-4ff6-881e-581dde95d511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Install rdkit library for molecules\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import DataStructs\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-18 15:25:01--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: Miniconda3-latest-Linux-x86_64.sh\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  15%[==>                 ]  10.72M  53.5MB/s               \r        Miniconda3-  49%[========>           ]  34.01M  83.5MB/s               \r       Miniconda3-l  75%[==============>     ]  51.94M  85.5MB/s               \rMiniconda3-latest-L 100%[===================>]  68.46M  87.5MB/s    in 0.8s    \n",
            "\n",
            "2020-01-18 15:25:02 (87.5 MB/s) - Miniconda3-latest-Linux-x86_64.sh saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m23.309s\n",
            "user\t0m7.210s\n",
            "sys\t0m2.607s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    conda-4.8.0                |           py37_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |py37h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_4         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc3755c2_3         568 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-7.0.0               |   py37hb39fc2d_0         598 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.09.3            |   py37hb31dc5d_0        23.7 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       108.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-py37h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_4\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_6\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_3\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.0.0-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.09.3-py37hb31dc5d_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m36.602s\n",
            "user\t0m29.880s\n",
            "sys\t0m3.363s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUpBu87UKvtv",
        "colab_type": "code",
        "outputId": "77632e5b-9b53-4763-df15-63c5fc6925f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"# Install PyTorch Geometry \n",
        "! pip install --verbose --no-cache-dir torch-scatter\n",
        "! pip install --verbose --no-cache-dir torch-sparse\n",
        "! pip install --verbose --no-cache-dir torch-cluster\n",
        "! pip install --verbose --no-cache-dir torch-spline-conv (optional)\n",
        "! pip install torch-geometric\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Install PyTorch Geometry \\n! pip install --verbose --no-cache-dir torch-scatter\\n! pip install --verbose --no-cache-dir torch-sparse\\n! pip install --verbose --no-cache-dir torch-cluster\\n! pip install --verbose --no-cache-dir torch-spline-conv (optional)\\n! pip install torch-geometric\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZN2bDpKe1aR",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LR8fBZmJ6IT",
        "colab_type": "code",
        "outputId": "77f2b5b9-80f8-4d12-9a04-402876fcbc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"compound_1000.csv\")\n",
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "      <th>Score_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1</td>\n",
              "      <td>-30.421166</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1</td>\n",
              "      <td>-20.839885</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F</td>\n",
              "      <td>-30.615744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F</td>\n",
              "      <td>-25.646399</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1</td>\n",
              "      <td>-29.502308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                        smi      Score  Score_bin\n",
              "0           0            NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1 -30.421166          1\n",
              "1           1       Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1 -20.839885          0\n",
              "2           2  O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F -30.615744          1\n",
              "3           3        CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F -25.646399          0\n",
              "4           4       CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1 -29.502308          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIwao6qhfEx4",
        "colab_type": "code",
        "outputId": "f7001322-d6fd-4743-f099-c860168f9bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = data[data.columns[1:3]]\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1</td>\n",
              "      <td>-30.421166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1</td>\n",
              "      <td>-20.839885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F</td>\n",
              "      <td>-30.615744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F</td>\n",
              "      <td>-25.646399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1</td>\n",
              "      <td>-29.502308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         smi      Score\n",
              "0            NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1 -30.421166\n",
              "1       Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1 -20.839885\n",
              "2  O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F -30.615744\n",
              "3        CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F -25.646399\n",
              "4       CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1 -29.502308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVkCbsv5fRPE",
        "colab_type": "code",
        "outputId": "772337f8-7fd6-4466-c811-51be9c75d0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "df.loc[df.Score>10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>CN(Cc1n[nH]c2c1CCCC2)C(=O)[C@H]1CCS(=O)(=O)C1</td>\n",
              "      <td>156.823354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              smi       Score\n",
              "50  CN(Cc1n[nH]c2c1CCCC2)C(=O)[C@H]1CCS(=O)(=O)C1  156.823354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzENvibXfUB_",
        "colab_type": "code",
        "outputId": "63a7aa88-4179-43fa-e8b4-002af43fba7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df_subset = df[:100]\n",
        "df_subset.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1</td>\n",
              "      <td>-30.421166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1</td>\n",
              "      <td>-20.839885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F</td>\n",
              "      <td>-30.615744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F</td>\n",
              "      <td>-25.646399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1</td>\n",
              "      <td>-29.502308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         smi      Score\n",
              "0            NC(=O)c1ccc(-c2ccc3ccccc3n2)cc1 -30.421166\n",
              "1       Nc1nc2nc(-c3ccccc3)cc(-c3ccccc3)n2n1 -20.839885\n",
              "2  O=C1[C@@H](N2CCc3cccc(F)c32)CCN1CC(F)(F)F -30.615744\n",
              "3        CSCc1cc(C(=O)N2CCc3[nH]ncc3C2)ccc1F -25.646399\n",
              "4       CC(=O)Nc1ccc(NC(=O)CSc2ccc(F)cc2)cc1 -29.502308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvWNBFmrfbWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGrrfywbgHca",
        "colab_type": "text"
      },
      "source": [
        "# Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC7klD_KgNkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbFx2nH05KWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import unicode_literals\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "import multiprocessing\n",
        "import logging\n",
        "\n",
        "# following code was borrowed from deepchem\n",
        "# https://raw.githubusercontent.com/deepchem/deepchem/master/deepchem/feat/graph_features.py\n",
        " \n",
        " \n",
        "def one_of_k_encoding(x, allowable_set):\n",
        "  if x not in allowable_set:\n",
        "    raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
        "        x, allowable_set))\n",
        "  return list(map(lambda s: x == s, allowable_set))\n",
        " \n",
        " \n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "  \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
        "  if x not in allowable_set:\n",
        "    x = allowable_set[-1]\n",
        "  return list(map(lambda s: x == s, allowable_set))\n",
        " \n",
        " \n",
        "def get_intervals(l):\n",
        "  \"\"\"For list of lists, gets the cumulative products of the lengths\"\"\"\n",
        "  intervals = len(l) * [0]\n",
        "  # Initalize with 1\n",
        "  intervals[0] = 1\n",
        "  for k in range(1, len(l)):\n",
        "    intervals[k] = (len(l[k]) + 1) * intervals[k - 1]\n",
        " \n",
        "  return intervals\n",
        " \n",
        " \n",
        "def safe_index(l, e):\n",
        "  \"\"\"Gets the index of e in l, providing an index of len(l) if not found\"\"\"\n",
        "  try:\n",
        "    return l.index(e)\n",
        "  except:\n",
        "    return len(l)\n",
        " \n",
        " \n",
        "possible_atom_list = [\n",
        "    'C', 'N', 'O', 'S', 'F', 'P', 'Cl', 'Mg', 'Na', 'Br', 'Fe', 'Ca', 'Cu',\n",
        "    'Mc', 'Pd', 'Pb', 'K', 'I', 'Al', 'Ni', 'Mn'\n",
        "]\n",
        "possible_numH_list = [0, 1, 2, 3, 4]\n",
        "possible_valence_list = [0, 1, 2, 3, 4, 5, 6]\n",
        "possible_formal_charge_list = [-3, -2, -1, 0, 1, 2, 3]\n",
        "possible_hybridization_list = [\n",
        "    Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
        "    Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
        "    Chem.rdchem.HybridizationType.SP3D2\n",
        "]\n",
        "possible_number_radical_e_list = [0, 1, 2]\n",
        "possible_chirality_list = ['R', 'S']\n",
        " \n",
        "reference_lists = [\n",
        "    possible_atom_list, possible_numH_list, possible_valence_list,\n",
        "    possible_formal_charge_list, possible_number_radical_e_list,\n",
        "    possible_hybridization_list, possible_chirality_list\n",
        "]\n",
        " \n",
        "intervals = get_intervals(reference_lists)\n",
        " \n",
        " \n",
        "def get_feature_list(atom):\n",
        "  features = 6 * [0]\n",
        "  features[0] = safe_index(possible_atom_list, atom.GetSymbol())\n",
        "  features[1] = safe_index(possible_numH_list, atom.GetTotalNumHs())\n",
        "  features[2] = safe_index(possible_valence_list, atom.GetImplicitValence())\n",
        "  features[3] = safe_index(possible_formal_charge_list, atom.GetFormalCharge())\n",
        "  features[4] = safe_index(possible_number_radical_e_list,\n",
        "                           atom.GetNumRadicalElectrons())\n",
        "  features[5] = safe_index(possible_hybridization_list, atom.GetHybridization())\n",
        "  return features\n",
        " \n",
        " \n",
        "def features_to_id(features, intervals):\n",
        "  \"\"\"Convert list of features into index using spacings provided in intervals\"\"\"\n",
        "  id = 0\n",
        "  for k in range(len(intervals)):\n",
        "    id += features[k] * intervals[k]\n",
        " \n",
        "  # Allow 0 index to correspond to null molecule 1\n",
        "  id = id + 1\n",
        "  return id\n",
        " \n",
        " \n",
        "def id_to_features(id, intervals):\n",
        "  features = 6 * [0]\n",
        " \n",
        "  # Correct for null\n",
        "  id -= 1\n",
        " \n",
        "  for k in range(0, 6 - 1):\n",
        "    # print(6-k-1, id)\n",
        "    features[6 - k - 1] = id // intervals[6 - k - 1]\n",
        "    id -= features[6 - k - 1] * intervals[6 - k - 1]\n",
        "  # Correct for last one\n",
        "  features[0] = id\n",
        "  return features\n",
        " \n",
        " \n",
        "def atom_to_id(atom):\n",
        "  \"\"\"Return a unique id corresponding to the atom type\"\"\"\n",
        "  features = get_feature_list(atom)\n",
        "  return features_to_id(features, intervals)\n",
        " \n",
        " \n",
        "def atom_features(atom,\n",
        "                  bool_id_feat=False,\n",
        "                  explicit_H=False,\n",
        "                  use_chirality=False):\n",
        "  if bool_id_feat:\n",
        "    return np.array([atom_to_id(atom)])\n",
        "  else:\n",
        "    from rdkit import Chem\n",
        "    results = one_of_k_encoding_unk(\n",
        "      atom.GetSymbol(),\n",
        "      [\n",
        "        'C',\n",
        "        'N',\n",
        "        'O',\n",
        "        'S',\n",
        "        'F',\n",
        "        'Si',\n",
        "        'P',\n",
        "        'Cl',\n",
        "        'Br',\n",
        "        'Mg',\n",
        "        'Na',\n",
        "        'Ca',\n",
        "        'Fe',\n",
        "        'As',\n",
        "        'Al',\n",
        "        'I',\n",
        "        'B',\n",
        "        'V',\n",
        "        'K',\n",
        "        'Tl',\n",
        "        'Yb',\n",
        "        'Sb',\n",
        "        'Sn',\n",
        "        'Ag',\n",
        "        'Pd',\n",
        "        'Co',\n",
        "        'Se',\n",
        "        'Ti',\n",
        "        'Zn',\n",
        "        'H',  # H?\n",
        "        'Li',\n",
        "        'Ge',\n",
        "        'Cu',\n",
        "        'Au',\n",
        "        'Ni',\n",
        "        'Cd',\n",
        "        'In',\n",
        "        'Mn',\n",
        "        'Zr',\n",
        "        'Cr',\n",
        "        'Pt',\n",
        "        'Hg',\n",
        "        'Pb',\n",
        "        'Unknown'\n",
        "      ]) + one_of_k_encoding(atom.GetDegree(),\n",
        "                             [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) + \\\n",
        "              one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]) + \\\n",
        "              [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
        "              one_of_k_encoding_unk(atom.GetHybridization(), [\n",
        "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
        "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.\n",
        "                                    SP3D, Chem.rdchem.HybridizationType.SP3D2\n",
        "              ]) + [atom.GetIsAromatic()]\n",
        "    # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
        "    if not explicit_H:\n",
        "      results = results + one_of_k_encoding_unk(atom.GetTotalNumHs(),\n",
        "                                                [0, 1, 2, 3, 4])\n",
        "    if use_chirality:\n",
        "      try:\n",
        "        results = results + one_of_k_encoding_unk(\n",
        "            atom.GetProp('_CIPCode'),\n",
        "            ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
        "      except:\n",
        "        results = results + [False, False\n",
        "                            ] + [atom.HasProp('_ChiralityPossible')]\n",
        " \n",
        "    return np.array(results)\n",
        " \n",
        " \n",
        "def bond_features(bond, use_chirality=False):\n",
        "  from rdkit import Chem\n",
        "  bt = bond.GetBondType()\n",
        "  bond_feats = [\n",
        "      bt == Chem.rdchem.BondType.SINGLE, bt == Chem.rdchem.BondType.DOUBLE,\n",
        "      bt == Chem.rdchem.BondType.TRIPLE, bt == Chem.rdchem.BondType.AROMATIC,\n",
        "      bond.GetIsConjugated(),\n",
        "      bond.IsInRing()\n",
        "  ]\n",
        "  if use_chirality:\n",
        "    bond_feats = bond_feats + one_of_k_encoding_unk(\n",
        "        str(bond.GetStereo()),\n",
        "        [\"STEREONONE\", \"STEREOANY\", \"STEREOZ\", \"STEREOE\"])\n",
        "  return np.array(bond_feats)\n",
        " \n",
        "#################\n",
        "# pen added\n",
        "#################\n",
        "def get_bond_pair(mol):\n",
        "  bonds = mol.GetBonds()\n",
        "  res = [[],[]]\n",
        "  for bond in bonds:\n",
        "    res[0] += [bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]\n",
        "    res[1] += [bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]\n",
        "  return res\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRI51sHL5azW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mol2vec(mol):\n",
        "  atoms = mol.GetAtoms()\n",
        "  bonds = mol.GetBonds()\n",
        "  node_f= [atom_features(atom) for atom in atoms]\n",
        "  edge_index = get_bond_pair(mol)\n",
        "  edge_attr = [bond_features(bond, use_chirality=False) for bond in bonds]\n",
        "  for bond in bonds:\n",
        "    edge_attr.append(bond_features(bond))\n",
        "  data = Data(x=torch.tensor(node_f, dtype=torch.float),\n",
        "              edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
        "              edge_attr=torch.tensor(edge_attr,dtype=torch.float)\n",
        "              )\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oEbeK_hgW9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = [mol2vec(Chem.MolFromSmiles(m)) for m in df_subset.smi]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMSlKa5SgZiq",
        "colab_type": "code",
        "outputId": "101a32b6-6afb-4e1f-c47e-85ed79160a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(train_X[0])\n",
        "print(train_X[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data(edge_attr=[42, 6], edge_index=[2, 42], x=[19, 75])\n",
            "Data(edge_attr=[50, 6], edge_index=[2, 50], x=[22, 75])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OSjDMx8hXu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, data in enumerate(train_X):\n",
        "    data.y = torch.tensor([df_subset.Score.values[i]], dtype=torch.float)\n",
        "    #print(data.y)\n",
        "    #Scores in torch format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJenJm8i_Y3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkk5Lv85iYtu",
        "colab_type": "code",
        "outputId": "6372815e-7555-4894-98ac-bac5a245472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df_subset_test = df[200:250]\n",
        "df_subset_test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>C[C@H](NC(=O)c1cccs1)C(=O)Nc1ccc2scnc2c1</td>\n",
              "      <td>-21.858306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>CNC(=O)CN1CCC(NC(=O)C2(c3cccc(C)c3)CC2)CC1</td>\n",
              "      <td>-17.542412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>Cc1nc(-n2nc(C)c(Cc3ccc(C)cc3)c2O)sc1C(=O)N1CCCC1</td>\n",
              "      <td>-20.483000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>O=C(Nc1ccc2c(c1)COC2)N1CCC[C@H]1Cc1ccccc1</td>\n",
              "      <td>-32.402423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>Cc1cccc(F)c1NC(=O)NC[C@H]1CCC[C@@]12NC(=O)NC2=O</td>\n",
              "      <td>-22.204779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  smi      Score\n",
              "200          C[C@H](NC(=O)c1cccs1)C(=O)Nc1ccc2scnc2c1 -21.858306\n",
              "201        CNC(=O)CN1CCC(NC(=O)C2(c3cccc(C)c3)CC2)CC1 -17.542412\n",
              "202  Cc1nc(-n2nc(C)c(Cc3ccc(C)cc3)c2O)sc1C(=O)N1CCCC1 -20.483000\n",
              "203         O=C(Nc1ccc2c(c1)COC2)N1CCC[C@H]1Cc1ccccc1 -32.402423\n",
              "204   Cc1cccc(F)c1NC(=O)NC[C@H]1CCC[C@@]12NC(=O)NC2=O -22.204779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuQPWH_Cikzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = [mol2vec(Chem.MolFromSmiles(m)) for m in df_subset_test.smi]\n",
        "for i, data in enumerate(test_X):\n",
        "    data.y = torch.tensor([df_subset_test.Score.values[i]], dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c32jSMEaAugs",
        "colab_type": "code",
        "outputId": "3a458808-15bb-4339-ed60-17c802caf646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "df_subset_valid = df[400:500]\n",
        "df_subset_valid.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smi</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>CCCc1ccc(OC[C@H](O)CN[C@@H](C)c2ccccc2)cc1</td>\n",
              "      <td>-26.091187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>Cc1ccc(CNC(=O)NC[C@@H]2CC[C@H](O)C2)c(OC(C)C)c1</td>\n",
              "      <td>-22.168625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>COc1cccc([C@H]2C(C(=O)OC[C@@H]3CCCO3)=C(C)Nc3n...</td>\n",
              "      <td>-23.054237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>CN1CCN(c2ncccc2C(F)(F)F)C[C@]12CCC(=O)N(C)CC2</td>\n",
              "      <td>-20.186395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>C[C@@H]1CCCCN1C(=O)CCN1C(=O)c2ccccc2C1=O</td>\n",
              "      <td>-20.124849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   smi      Score\n",
              "400         CCCc1ccc(OC[C@H](O)CN[C@@H](C)c2ccccc2)cc1 -26.091187\n",
              "401    Cc1ccc(CNC(=O)NC[C@@H]2CC[C@H](O)C2)c(OC(C)C)c1 -22.168625\n",
              "402  COc1cccc([C@H]2C(C(=O)OC[C@@H]3CCCO3)=C(C)Nc3n... -23.054237\n",
              "403      CN1CCN(c2ncccc2C(F)(F)F)C[C@]12CCC(=O)N(C)CC2 -20.186395\n",
              "404           C[C@@H]1CCCCN1C(=O)CCN1C(=O)c2ccccc2C1=O -20.124849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of7BGUg9dAGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "valid_X = [mol2vec(Chem.MolFromSmiles(m)) for m in df_subset_valid.smi]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0cBDMjzcO02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, data in enumerate(valid_X):\n",
        "  data.y = torch.tensor([df_subset_valid.Score.values[i]], dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10w90Pe5iveA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_X, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(valid_X, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_X, batch_size=128, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Egma8qwwDK",
        "colab_type": "code",
        "outputId": "f5e2d106-f114-41b5-d908-31442c3ea8b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_loader"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch_geometric.data.dataloader.DataLoader at 0x7fe324cde908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHU2Mo9v29z",
        "colab_type": "text"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B50DkXcki4Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import NNConv, Set2Set #NNConv (implemented MPNN); Set2Set \n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import remove_self_loops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dRjczfpi6pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = 75\n",
        "dim = 64\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    \n",
        "    self.lin0 = torch.nn.Linear(n_features, dim)\n",
        "    nn = Sequential(Linear(6, 128), ReLU(), Linear(128, dim*dim))\n",
        "    self.conv = NNConv(dim, dim, nn, aggr = 'mean')\n",
        "    self.gru = GRU(dim, dim)\n",
        "\n",
        "    self.set2set = Set2Set(dim, processing_steps=3)\n",
        "    self.lin1 = torch.nn.Linear(2*dim, dim)\n",
        "    self.lin2 = torch.nn.Linear(dim, 1)\n",
        "\n",
        "  def forward(self, data):\n",
        "    out = F.relu(self.lin0(data.x))\n",
        "    h = out.unsqueeze(0)\n",
        "\n",
        "    for i in range(3):\n",
        "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
        "            out, h = self.gru(m.unsqueeze(0), h)\n",
        "            out = out.squeeze(0)\n",
        "\n",
        "    out = self.set2set(out, data.batch)\n",
        "    out = F.relu(self.lin1(out))\n",
        "    out = self.lin2(out)\n",
        "    return out.view(-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net().to(device)\n",
        "#data = data.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',factor=0.7, patience=5,min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbI_3xY5YtKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBvKcK6vVH0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data) #error 1-dim data\n",
        "        loss = F.mse_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "        #Loss = total_loss / len(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGIWu2u0VLmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in test_loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "    return correct / len(test_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8zNRif_dkJP",
        "colab_type": "code",
        "outputId": "48422b06-c96f-4bb6-c739-1af3c99eb808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = F.mse_loss(model(data), data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        error += (model(data)  - data.y ).abs().sum().item()  # MAE\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "best_val_error = None\n",
        "for epoch in range(1, 301):\n",
        "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "    loss = train(epoch)\n",
        "    val_error = test(val_loader)\n",
        "    scheduler.step(val_error)\n",
        "\n",
        "    if best_val_error is None or val_error <= best_val_error:\n",
        "        test_error = test(test_loader)\n",
        "        best_val_error = val_error\n",
        "\n",
        "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
        "           'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, LR: 0.001000, Loss: 121.3498535, Validation MAE: 5.8672504, Test MAE: 4.8414001\n",
            "Epoch: 002, LR: 0.001000, Loss: 116.8375702, Validation MAE: 5.7766858, Test MAE: 4.9580688\n",
            "Epoch: 003, LR: 0.001000, Loss: 113.6310806, Validation MAE: 6.2931104, Test MAE: 4.9580688\n",
            "Epoch: 004, LR: 0.001000, Loss: 108.9976501, Validation MAE: 6.2689575, Test MAE: 4.9580688\n",
            "Epoch: 005, LR: 0.001000, Loss: 105.1801529, Validation MAE: 5.9865857, Test MAE: 4.9580688\n",
            "Epoch: 006, LR: 0.001000, Loss: 101.9528809, Validation MAE: 5.9973212, Test MAE: 4.9580688\n",
            "Epoch: 007, LR: 0.001000, Loss: 98.0595779, Validation MAE: 6.2380164, Test MAE: 4.9580688\n",
            "Epoch: 008, LR: 0.001000, Loss: 94.3852615, Validation MAE: 5.9604663, Test MAE: 4.9580688\n",
            "Epoch: 009, LR: 0.001000, Loss: 90.6614685, Validation MAE: 5.7398767, Test MAE: 4.8111118\n",
            "Epoch: 010, LR: 0.001000, Loss: 87.8432388, Validation MAE: 5.8944568, Test MAE: 4.8111118\n",
            "Epoch: 011, LR: 0.001000, Loss: 84.3196106, Validation MAE: 6.0037189, Test MAE: 4.8111118\n",
            "Epoch: 012, LR: 0.001000, Loss: 81.0434341, Validation MAE: 5.8541187, Test MAE: 4.8111118\n",
            "Epoch: 013, LR: 0.001000, Loss: 77.7729797, Validation MAE: 6.0617224, Test MAE: 4.8111118\n",
            "Epoch: 014, LR: 0.001000, Loss: 74.5876465, Validation MAE: 6.4170642, Test MAE: 4.8111118\n",
            "Epoch: 015, LR: 0.001000, Loss: 72.2173462, Validation MAE: 6.0013037, Test MAE: 4.8111118\n",
            "Epoch: 016, LR: 0.001000, Loss: 69.6461639, Validation MAE: 6.5164301, Test MAE: 4.8111118\n",
            "Epoch: 017, LR: 0.001000, Loss: 66.4022522, Validation MAE: 6.7950165, Test MAE: 4.8111118\n",
            "Epoch: 018, LR: 0.001000, Loss: 63.9052429, Validation MAE: 6.3232996, Test MAE: 4.8111118\n",
            "Epoch: 019, LR: 0.001000, Loss: 61.1681900, Validation MAE: 6.5032593, Test MAE: 4.8111118\n",
            "Epoch: 020, LR: 0.001000, Loss: 58.3005676, Validation MAE: 7.3082550, Test MAE: 4.8111118\n",
            "Epoch: 021, LR: 0.001000, Loss: 56.0829506, Validation MAE: 6.7306152, Test MAE: 4.8111118\n",
            "Epoch: 022, LR: 0.001000, Loss: 54.6266365, Validation MAE: 7.3368695, Test MAE: 4.8111118\n",
            "Epoch: 023, LR: 0.001000, Loss: 52.0283890, Validation MAE: 7.2667322, Test MAE: 4.8111118\n",
            "Epoch: 024, LR: 0.001000, Loss: 49.7611923, Validation MAE: 7.2029175, Test MAE: 4.8111118\n",
            "Epoch: 025, LR: 0.001000, Loss: 47.9774742, Validation MAE: 7.7214856, Test MAE: 4.8111118\n",
            "Epoch: 026, LR: 0.001000, Loss: 45.9294586, Validation MAE: 7.5110193, Test MAE: 4.8111118\n",
            "Epoch: 027, LR: 0.001000, Loss: 43.8634567, Validation MAE: 7.4554590, Test MAE: 4.8111118\n",
            "Epoch: 028, LR: 0.001000, Loss: 42.5073967, Validation MAE: 6.7563605, Test MAE: 4.8111118\n",
            "Epoch: 029, LR: 0.001000, Loss: 40.7046471, Validation MAE: 6.8062823, Test MAE: 4.8111118\n",
            "Epoch: 030, LR: 0.001000, Loss: 39.0202637, Validation MAE: 8.0371222, Test MAE: 4.8111118\n",
            "Epoch: 031, LR: 0.001000, Loss: 38.3466835, Validation MAE: 6.6647644, Test MAE: 4.8111118\n",
            "Epoch: 032, LR: 0.001000, Loss: 37.0904045, Validation MAE: 7.2558142, Test MAE: 4.8111118\n",
            "Epoch: 033, LR: 0.001000, Loss: 35.9061241, Validation MAE: 7.0739709, Test MAE: 4.8111118\n",
            "Epoch: 034, LR: 0.001000, Loss: 34.4874344, Validation MAE: 6.7980688, Test MAE: 4.8111118\n",
            "Epoch: 035, LR: 0.001000, Loss: 33.4434319, Validation MAE: 7.8233228, Test MAE: 4.8111118\n",
            "Epoch: 036, LR: 0.001000, Loss: 32.2288666, Validation MAE: 8.1903711, Test MAE: 4.8111118\n",
            "Epoch: 037, LR: 0.001000, Loss: 31.7830887, Validation MAE: 7.1060144, Test MAE: 4.8111118\n",
            "Epoch: 038, LR: 0.001000, Loss: 30.7933693, Validation MAE: 7.2953967, Test MAE: 4.8111118\n",
            "Epoch: 039, LR: 0.001000, Loss: 29.4318924, Validation MAE: 7.2958667, Test MAE: 4.8111118\n",
            "Epoch: 040, LR: 0.001000, Loss: 29.5162792, Validation MAE: 6.8325464, Test MAE: 4.8111118\n",
            "Epoch: 041, LR: 0.001000, Loss: 28.3656158, Validation MAE: 6.9629883, Test MAE: 4.8111118\n",
            "Epoch: 042, LR: 0.001000, Loss: 27.7092133, Validation MAE: 7.9360291, Test MAE: 4.8111118\n",
            "Epoch: 043, LR: 0.001000, Loss: 27.4120388, Validation MAE: 7.6983789, Test MAE: 4.8111118\n",
            "Epoch: 044, LR: 0.001000, Loss: 26.5277271, Validation MAE: 7.2101953, Test MAE: 4.8111118\n",
            "Epoch: 045, LR: 0.001000, Loss: 26.5211163, Validation MAE: 7.9534021, Test MAE: 4.8111118\n",
            "Epoch: 046, LR: 0.001000, Loss: 26.0506439, Validation MAE: 7.9017822, Test MAE: 4.8111118\n",
            "Epoch: 047, LR: 0.001000, Loss: 26.0587044, Validation MAE: 7.1522089, Test MAE: 4.8111118\n",
            "Epoch: 048, LR: 0.001000, Loss: 25.8982563, Validation MAE: 7.5413989, Test MAE: 4.8111118\n",
            "Epoch: 049, LR: 0.001000, Loss: 24.6969681, Validation MAE: 8.1058435, Test MAE: 4.8111118\n",
            "Epoch: 050, LR: 0.001000, Loss: 24.8706589, Validation MAE: 7.7509442, Test MAE: 4.8111118\n",
            "Epoch: 051, LR: 0.001000, Loss: 24.1333618, Validation MAE: 7.3354456, Test MAE: 4.8111118\n",
            "Epoch: 052, LR: 0.001000, Loss: 24.6746063, Validation MAE: 8.1978186, Test MAE: 4.8111118\n",
            "Epoch: 053, LR: 0.001000, Loss: 24.7316608, Validation MAE: 7.6916785, Test MAE: 4.8111118\n",
            "Epoch: 054, LR: 0.001000, Loss: 23.9995823, Validation MAE: 6.7738770, Test MAE: 4.8111118\n",
            "Epoch: 055, LR: 0.001000, Loss: 24.9321518, Validation MAE: 7.3818860, Test MAE: 4.8111118\n",
            "Epoch: 056, LR: 0.001000, Loss: 23.1364117, Validation MAE: 8.3273364, Test MAE: 4.8111118\n",
            "Epoch: 057, LR: 0.001000, Loss: 24.5568466, Validation MAE: 7.2615540, Test MAE: 4.8111118\n",
            "Epoch: 058, LR: 0.001000, Loss: 23.2201004, Validation MAE: 7.1182568, Test MAE: 4.8111118\n",
            "Epoch: 059, LR: 0.001000, Loss: 23.1747055, Validation MAE: 7.8375781, Test MAE: 4.8111118\n",
            "Epoch: 060, LR: 0.001000, Loss: 22.7473564, Validation MAE: 8.0020422, Test MAE: 4.8111118\n",
            "Epoch: 061, LR: 0.001000, Loss: 23.1105175, Validation MAE: 7.5498499, Test MAE: 4.8111118\n",
            "Epoch: 062, LR: 0.001000, Loss: 22.7633343, Validation MAE: 7.5033258, Test MAE: 4.8111118\n",
            "Epoch: 063, LR: 0.001000, Loss: 22.4406548, Validation MAE: 7.7294922, Test MAE: 4.8111118\n",
            "Epoch: 064, LR: 0.001000, Loss: 22.4015160, Validation MAE: 7.8000415, Test MAE: 4.8111118\n",
            "Epoch: 065, LR: 0.001000, Loss: 22.4159489, Validation MAE: 7.7057031, Test MAE: 4.8111118\n",
            "Epoch: 066, LR: 0.001000, Loss: 22.1828423, Validation MAE: 7.7372699, Test MAE: 4.8111118\n",
            "Epoch: 067, LR: 0.001000, Loss: 21.9638157, Validation MAE: 7.8517163, Test MAE: 4.8111118\n",
            "Epoch: 068, LR: 0.001000, Loss: 21.9348412, Validation MAE: 7.9131604, Test MAE: 4.8111118\n",
            "Epoch: 069, LR: 0.001000, Loss: 21.8570995, Validation MAE: 7.8665314, Test MAE: 4.8111118\n",
            "Epoch: 070, LR: 0.001000, Loss: 21.5275154, Validation MAE: 7.9189502, Test MAE: 4.8111118\n",
            "Epoch: 071, LR: 0.001000, Loss: 21.4812794, Validation MAE: 7.8805719, Test MAE: 4.8111118\n",
            "Epoch: 072, LR: 0.001000, Loss: 21.5669918, Validation MAE: 7.8429309, Test MAE: 4.8111118\n",
            "Epoch: 073, LR: 0.001000, Loss: 21.2858620, Validation MAE: 7.9660413, Test MAE: 4.8111118\n",
            "Epoch: 074, LR: 0.001000, Loss: 21.1162872, Validation MAE: 7.9283887, Test MAE: 4.8111118\n",
            "Epoch: 075, LR: 0.001000, Loss: 21.1043682, Validation MAE: 7.9702417, Test MAE: 4.8111118\n",
            "Epoch: 076, LR: 0.001000, Loss: 20.9776249, Validation MAE: 8.1528564, Test MAE: 4.8111118\n",
            "Epoch: 077, LR: 0.001000, Loss: 20.8218117, Validation MAE: 8.0196191, Test MAE: 4.8111118\n",
            "Epoch: 078, LR: 0.001000, Loss: 20.7706490, Validation MAE: 8.0412292, Test MAE: 4.8111118\n",
            "Epoch: 079, LR: 0.001000, Loss: 20.6317062, Validation MAE: 7.8298523, Test MAE: 4.8111118\n",
            "Epoch: 080, LR: 0.001000, Loss: 20.5623360, Validation MAE: 7.8163037, Test MAE: 4.8111118\n",
            "Epoch: 081, LR: 0.001000, Loss: 20.4922924, Validation MAE: 7.9762744, Test MAE: 4.8111118\n",
            "Epoch: 082, LR: 0.001000, Loss: 20.4397354, Validation MAE: 7.8463672, Test MAE: 4.8111118\n",
            "Epoch: 083, LR: 0.001000, Loss: 20.3482456, Validation MAE: 7.6879681, Test MAE: 4.8111118\n",
            "Epoch: 084, LR: 0.001000, Loss: 20.2816257, Validation MAE: 7.7280469, Test MAE: 4.8111118\n",
            "Epoch: 085, LR: 0.001000, Loss: 20.2308521, Validation MAE: 7.5822754, Test MAE: 4.8111118\n",
            "Epoch: 086, LR: 0.001000, Loss: 20.1606789, Validation MAE: 7.5718256, Test MAE: 4.8111118\n",
            "Epoch: 087, LR: 0.001000, Loss: 20.1181335, Validation MAE: 7.7388831, Test MAE: 4.8111118\n",
            "Epoch: 088, LR: 0.001000, Loss: 20.0727863, Validation MAE: 7.6572943, Test MAE: 4.8111118\n",
            "Epoch: 089, LR: 0.001000, Loss: 20.0036469, Validation MAE: 7.6501257, Test MAE: 4.8111118\n",
            "Epoch: 090, LR: 0.001000, Loss: 19.9275284, Validation MAE: 7.6988440, Test MAE: 4.8111118\n",
            "Epoch: 091, LR: 0.001000, Loss: 19.8807335, Validation MAE: 7.5572021, Test MAE: 4.8111118\n",
            "Epoch: 092, LR: 0.001000, Loss: 19.8303375, Validation MAE: 7.5409680, Test MAE: 4.8111118\n",
            "Epoch: 093, LR: 0.001000, Loss: 19.7503262, Validation MAE: 7.5713525, Test MAE: 4.8111118\n",
            "Epoch: 094, LR: 0.001000, Loss: 19.6586552, Validation MAE: 7.5408142, Test MAE: 4.8111118\n",
            "Epoch: 095, LR: 0.001000, Loss: 19.5533695, Validation MAE: 7.6762109, Test MAE: 4.8111118\n",
            "Epoch: 096, LR: 0.001000, Loss: 19.4565964, Validation MAE: 7.6105469, Test MAE: 4.8111118\n",
            "Epoch: 097, LR: 0.001000, Loss: 19.3431854, Validation MAE: 7.7007965, Test MAE: 4.8111118\n",
            "Epoch: 098, LR: 0.001000, Loss: 19.2143230, Validation MAE: 7.9092773, Test MAE: 4.8111118\n",
            "Epoch: 099, LR: 0.001000, Loss: 19.0702648, Validation MAE: 7.8793713, Test MAE: 4.8111118\n",
            "Epoch: 100, LR: 0.001000, Loss: 18.9018040, Validation MAE: 8.0217542, Test MAE: 4.8111118\n",
            "Epoch: 101, LR: 0.001000, Loss: 18.7425404, Validation MAE: 7.9490076, Test MAE: 4.8111118\n",
            "Epoch: 102, LR: 0.001000, Loss: 18.6277885, Validation MAE: 7.9323071, Test MAE: 4.8111118\n",
            "Epoch: 103, LR: 0.001000, Loss: 18.5144482, Validation MAE: 7.8159888, Test MAE: 4.8111118\n",
            "Epoch: 104, LR: 0.001000, Loss: 18.4126892, Validation MAE: 7.8893848, Test MAE: 4.8111118\n",
            "Epoch: 105, LR: 0.001000, Loss: 18.3098183, Validation MAE: 7.7299359, Test MAE: 4.8111118\n",
            "Epoch: 106, LR: 0.001000, Loss: 18.3216171, Validation MAE: 8.3376111, Test MAE: 4.8111118\n",
            "Epoch: 107, LR: 0.001000, Loss: 18.8985806, Validation MAE: 6.7881989, Test MAE: 4.8111118\n",
            "Epoch: 108, LR: 0.001000, Loss: 22.2136650, Validation MAE: 12.4594702, Test MAE: 4.8111118\n",
            "Epoch: 109, LR: 0.001000, Loss: 28.8751507, Validation MAE: 7.7520782, Test MAE: 4.8111118\n",
            "Epoch: 110, LR: 0.001000, Loss: 23.0735474, Validation MAE: 6.6032910, Test MAE: 4.8111118\n",
            "Epoch: 111, LR: 0.001000, Loss: 28.4167633, Validation MAE: 7.2291876, Test MAE: 4.8111118\n",
            "Epoch: 112, LR: 0.001000, Loss: 24.3035374, Validation MAE: 7.9844751, Test MAE: 4.8111118\n",
            "Epoch: 113, LR: 0.001000, Loss: 26.3962116, Validation MAE: 7.8942352, Test MAE: 4.8111118\n",
            "Epoch: 114, LR: 0.001000, Loss: 23.6498928, Validation MAE: 7.7342316, Test MAE: 4.8111118\n",
            "Epoch: 115, LR: 0.001000, Loss: 21.6108665, Validation MAE: 8.1093347, Test MAE: 4.8111118\n",
            "Epoch: 116, LR: 0.001000, Loss: 23.0077190, Validation MAE: 11.0936145, Test MAE: 4.8111118\n",
            "Epoch: 117, LR: 0.001000, Loss: 28.8997478, Validation MAE: 6.7974878, Test MAE: 4.8111118\n",
            "Epoch: 118, LR: 0.001000, Loss: 22.5124340, Validation MAE: 5.5654352, Test MAE: 4.8610559\n",
            "Epoch: 119, LR: 0.001000, Loss: 28.4689770, Validation MAE: 5.5946844, Test MAE: 4.8610559\n",
            "Epoch: 120, LR: 0.001000, Loss: 26.2626705, Validation MAE: 5.5816479, Test MAE: 4.8610559\n",
            "Epoch: 121, LR: 0.001000, Loss: 25.4091949, Validation MAE: 5.5599963, Test MAE: 4.4908127\n",
            "Epoch: 122, LR: 0.001000, Loss: 24.5638885, Validation MAE: 5.4409235, Test MAE: 4.5618533\n",
            "Epoch: 123, LR: 0.001000, Loss: 25.6996441, Validation MAE: 5.4581842, Test MAE: 4.5618533\n",
            "Epoch: 124, LR: 0.001000, Loss: 24.6828327, Validation MAE: 5.5832355, Test MAE: 4.5618533\n",
            "Epoch: 125, LR: 0.001000, Loss: 23.0396233, Validation MAE: 6.1360144, Test MAE: 4.5618533\n",
            "Epoch: 126, LR: 0.001000, Loss: 24.7536449, Validation MAE: 6.9135669, Test MAE: 4.5618533\n",
            "Epoch: 127, LR: 0.001000, Loss: 23.5885963, Validation MAE: 6.9536511, Test MAE: 4.5618533\n",
            "Epoch: 128, LR: 0.001000, Loss: 23.7996216, Validation MAE: 7.1531738, Test MAE: 4.5618533\n",
            "Epoch: 129, LR: 0.001000, Loss: 24.0751419, Validation MAE: 7.3995880, Test MAE: 4.5618533\n",
            "Epoch: 130, LR: 0.001000, Loss: 22.6436672, Validation MAE: 7.6367920, Test MAE: 4.5618533\n",
            "Epoch: 131, LR: 0.001000, Loss: 22.6836281, Validation MAE: 7.5100952, Test MAE: 4.5618533\n",
            "Epoch: 132, LR: 0.001000, Loss: 21.5164719, Validation MAE: 7.3033252, Test MAE: 4.5618533\n",
            "Epoch: 133, LR: 0.001000, Loss: 21.4223576, Validation MAE: 7.1622656, Test MAE: 4.5618533\n",
            "Epoch: 134, LR: 0.001000, Loss: 21.1496334, Validation MAE: 7.1209204, Test MAE: 4.5618533\n",
            "Epoch: 135, LR: 0.001000, Loss: 20.9582710, Validation MAE: 7.0148077, Test MAE: 4.5618533\n",
            "Epoch: 136, LR: 0.001000, Loss: 20.5447140, Validation MAE: 6.9259436, Test MAE: 4.5618533\n",
            "Epoch: 137, LR: 0.001000, Loss: 20.5336628, Validation MAE: 7.0416602, Test MAE: 4.5618533\n",
            "Epoch: 138, LR: 0.001000, Loss: 20.4326687, Validation MAE: 7.3726300, Test MAE: 4.5618533\n",
            "Epoch: 139, LR: 0.001000, Loss: 20.1101646, Validation MAE: 7.5502887, Test MAE: 4.5618533\n",
            "Epoch: 140, LR: 0.001000, Loss: 19.9049625, Validation MAE: 7.4794800, Test MAE: 4.5618533\n",
            "Epoch: 141, LR: 0.001000, Loss: 19.4377556, Validation MAE: 7.4994519, Test MAE: 4.5618533\n",
            "Epoch: 142, LR: 0.001000, Loss: 19.2909698, Validation MAE: 7.6552966, Test MAE: 4.5618533\n",
            "Epoch: 143, LR: 0.001000, Loss: 18.9077320, Validation MAE: 7.7581091, Test MAE: 4.5618533\n",
            "Epoch: 144, LR: 0.001000, Loss: 18.8654156, Validation MAE: 7.6675812, Test MAE: 4.5618533\n",
            "Epoch: 145, LR: 0.001000, Loss: 18.4951649, Validation MAE: 7.6199860, Test MAE: 4.5618533\n",
            "Epoch: 146, LR: 0.001000, Loss: 18.3792610, Validation MAE: 7.7317896, Test MAE: 4.5618533\n",
            "Epoch: 147, LR: 0.001000, Loss: 18.1073532, Validation MAE: 7.7558331, Test MAE: 4.5618533\n",
            "Epoch: 148, LR: 0.001000, Loss: 18.0774345, Validation MAE: 7.6078082, Test MAE: 4.5618533\n",
            "Epoch: 149, LR: 0.001000, Loss: 17.8171787, Validation MAE: 7.4943066, Test MAE: 4.5618533\n",
            "Epoch: 150, LR: 0.001000, Loss: 17.6825390, Validation MAE: 7.5023767, Test MAE: 4.5618533\n",
            "Epoch: 151, LR: 0.001000, Loss: 17.4551716, Validation MAE: 7.5019312, Test MAE: 4.5618533\n",
            "Epoch: 152, LR: 0.001000, Loss: 17.4032078, Validation MAE: 7.3877136, Test MAE: 4.5618533\n",
            "Epoch: 153, LR: 0.001000, Loss: 17.1886234, Validation MAE: 7.3258545, Test MAE: 4.5618533\n",
            "Epoch: 154, LR: 0.001000, Loss: 17.1180153, Validation MAE: 7.4072876, Test MAE: 4.5618533\n",
            "Epoch: 155, LR: 0.001000, Loss: 16.9398079, Validation MAE: 7.4927527, Test MAE: 4.5618533\n",
            "Epoch: 156, LR: 0.001000, Loss: 16.9077072, Validation MAE: 7.4402966, Test MAE: 4.5618533\n",
            "Epoch: 157, LR: 0.001000, Loss: 16.7641048, Validation MAE: 7.4456610, Test MAE: 4.5618533\n",
            "Epoch: 158, LR: 0.001000, Loss: 16.7359867, Validation MAE: 7.5643652, Test MAE: 4.5618533\n",
            "Epoch: 159, LR: 0.001000, Loss: 16.6762009, Validation MAE: 7.5689325, Test MAE: 4.5618533\n",
            "Epoch: 160, LR: 0.001000, Loss: 16.6016502, Validation MAE: 7.4880566, Test MAE: 4.5618533\n",
            "Epoch: 161, LR: 0.001000, Loss: 16.5441895, Validation MAE: 7.5024707, Test MAE: 4.5618533\n",
            "Epoch: 162, LR: 0.001000, Loss: 16.4311581, Validation MAE: 7.5279578, Test MAE: 4.5618533\n",
            "Epoch: 163, LR: 0.001000, Loss: 16.3970737, Validation MAE: 7.4179773, Test MAE: 4.5618533\n",
            "Epoch: 164, LR: 0.001000, Loss: 16.2948799, Validation MAE: 7.3546814, Test MAE: 4.5618533\n",
            "Epoch: 165, LR: 0.001000, Loss: 16.2577152, Validation MAE: 7.4011267, Test MAE: 4.5618533\n",
            "Epoch: 166, LR: 0.001000, Loss: 16.2271652, Validation MAE: 7.3592053, Test MAE: 4.5618533\n",
            "Epoch: 167, LR: 0.001000, Loss: 16.1778107, Validation MAE: 7.3488574, Test MAE: 4.5618533\n",
            "Epoch: 168, LR: 0.001000, Loss: 16.1587276, Validation MAE: 7.4750970, Test MAE: 4.5618533\n",
            "Epoch: 169, LR: 0.001000, Loss: 16.1115265, Validation MAE: 7.4524670, Test MAE: 4.5618533\n",
            "Epoch: 170, LR: 0.001000, Loss: 16.0287457, Validation MAE: 7.4801599, Test MAE: 4.5618533\n",
            "Epoch: 171, LR: 0.001000, Loss: 15.9673605, Validation MAE: 7.5548151, Test MAE: 4.5618533\n",
            "Epoch: 172, LR: 0.001000, Loss: 15.9297295, Validation MAE: 7.4656641, Test MAE: 4.5618533\n",
            "Epoch: 173, LR: 0.001000, Loss: 15.8898840, Validation MAE: 7.5357825, Test MAE: 4.5618533\n",
            "Epoch: 174, LR: 0.001000, Loss: 15.8196945, Validation MAE: 7.5270837, Test MAE: 4.5618533\n",
            "Epoch: 175, LR: 0.001000, Loss: 15.7689638, Validation MAE: 7.3826105, Test MAE: 4.5618533\n",
            "Epoch: 176, LR: 0.001000, Loss: 15.7403450, Validation MAE: 7.4362305, Test MAE: 4.5618533\n",
            "Epoch: 177, LR: 0.001000, Loss: 15.7346725, Validation MAE: 7.1328107, Test MAE: 4.5618533\n",
            "Epoch: 178, LR: 0.001000, Loss: 15.6687317, Validation MAE: 7.1664832, Test MAE: 4.5618533\n",
            "Epoch: 179, LR: 0.001000, Loss: 15.5909176, Validation MAE: 7.0423389, Test MAE: 4.5618533\n",
            "Epoch: 180, LR: 0.001000, Loss: 15.5321608, Validation MAE: 6.8336865, Test MAE: 4.5618533\n",
            "Epoch: 181, LR: 0.001000, Loss: 15.5075264, Validation MAE: 6.9410382, Test MAE: 4.5618533\n",
            "Epoch: 182, LR: 0.001000, Loss: 15.4940548, Validation MAE: 6.6539081, Test MAE: 4.5618533\n",
            "Epoch: 183, LR: 0.001000, Loss: 15.5036964, Validation MAE: 6.8390186, Test MAE: 4.5618533\n",
            "Epoch: 184, LR: 0.001000, Loss: 15.4856901, Validation MAE: 6.5289734, Test MAE: 4.5618533\n",
            "Epoch: 185, LR: 0.001000, Loss: 15.4461088, Validation MAE: 6.7197070, Test MAE: 4.5618533\n",
            "Epoch: 186, LR: 0.001000, Loss: 15.3387623, Validation MAE: 6.5336749, Test MAE: 4.5618533\n",
            "Epoch: 187, LR: 0.001000, Loss: 15.2365866, Validation MAE: 6.5566248, Test MAE: 4.5618533\n",
            "Epoch: 188, LR: 0.001000, Loss: 15.1695814, Validation MAE: 6.6224231, Test MAE: 4.5618533\n",
            "Epoch: 189, LR: 0.001000, Loss: 15.1490335, Validation MAE: 6.4900397, Test MAE: 4.5618533\n",
            "Epoch: 190, LR: 0.001000, Loss: 15.1462650, Validation MAE: 6.7415295, Test MAE: 4.5618533\n",
            "Epoch: 191, LR: 0.001000, Loss: 15.1940346, Validation MAE: 6.5502478, Test MAE: 4.5618533\n",
            "Epoch: 192, LR: 0.001000, Loss: 15.0819349, Validation MAE: 6.5680469, Test MAE: 4.5618533\n",
            "Epoch: 193, LR: 0.001000, Loss: 14.9577208, Validation MAE: 6.6451111, Test MAE: 4.5618533\n",
            "Epoch: 194, LR: 0.001000, Loss: 14.9984818, Validation MAE: 6.4056604, Test MAE: 4.5618533\n",
            "Epoch: 195, LR: 0.001000, Loss: 14.9918785, Validation MAE: 6.5964966, Test MAE: 4.5618533\n",
            "Epoch: 196, LR: 0.001000, Loss: 14.8541431, Validation MAE: 6.5061450, Test MAE: 4.5618533\n",
            "Epoch: 197, LR: 0.001000, Loss: 14.7061796, Validation MAE: 6.4862024, Test MAE: 4.5618533\n",
            "Epoch: 198, LR: 0.001000, Loss: 14.6668711, Validation MAE: 6.6569952, Test MAE: 4.5618533\n",
            "Epoch: 199, LR: 0.001000, Loss: 14.6309595, Validation MAE: 6.5721753, Test MAE: 4.5618533\n",
            "Epoch: 200, LR: 0.001000, Loss: 14.4752922, Validation MAE: 6.6436108, Test MAE: 4.5618533\n",
            "Epoch: 201, LR: 0.001000, Loss: 14.3244286, Validation MAE: 6.7894739, Test MAE: 4.5618533\n",
            "Epoch: 202, LR: 0.001000, Loss: 14.3013391, Validation MAE: 6.3250818, Test MAE: 4.5618533\n",
            "Epoch: 203, LR: 0.001000, Loss: 14.9026928, Validation MAE: 6.7627698, Test MAE: 4.5618533\n",
            "Epoch: 204, LR: 0.001000, Loss: 14.6556396, Validation MAE: 6.4348535, Test MAE: 4.5618533\n",
            "Epoch: 205, LR: 0.001000, Loss: 13.9478903, Validation MAE: 6.6397424, Test MAE: 4.5618533\n",
            "Epoch: 206, LR: 0.001000, Loss: 14.1381693, Validation MAE: 6.3884167, Test MAE: 4.5618533\n",
            "Epoch: 207, LR: 0.001000, Loss: 13.8435059, Validation MAE: 6.8134192, Test MAE: 4.5618533\n",
            "Epoch: 208, LR: 0.001000, Loss: 14.6952419, Validation MAE: 6.0441980, Test MAE: 4.5618533\n",
            "Epoch: 209, LR: 0.001000, Loss: 17.2373352, Validation MAE: 6.6270978, Test MAE: 4.5618533\n",
            "Epoch: 210, LR: 0.001000, Loss: 13.6996231, Validation MAE: 7.1544135, Test MAE: 4.5618533\n",
            "Epoch: 211, LR: 0.001000, Loss: 15.6751099, Validation MAE: 5.8553326, Test MAE: 4.5618533\n",
            "Epoch: 212, LR: 0.001000, Loss: 20.4495964, Validation MAE: 6.0356409, Test MAE: 4.5618533\n",
            "Epoch: 213, LR: 0.001000, Loss: 16.0411148, Validation MAE: 7.6113074, Test MAE: 4.5618533\n",
            "Epoch: 214, LR: 0.001000, Loss: 19.8617249, Validation MAE: 6.0992151, Test MAE: 4.5618533\n",
            "Epoch: 215, LR: 0.001000, Loss: 14.7651281, Validation MAE: 5.7311633, Test MAE: 4.5618533\n",
            "Epoch: 216, LR: 0.001000, Loss: 17.0191956, Validation MAE: 5.7241907, Test MAE: 4.5618533\n",
            "Epoch: 217, LR: 0.001000, Loss: 16.4200153, Validation MAE: 5.9543085, Test MAE: 4.5618533\n",
            "Epoch: 218, LR: 0.001000, Loss: 16.0562344, Validation MAE: 5.9175031, Test MAE: 4.5618533\n",
            "Epoch: 219, LR: 0.001000, Loss: 14.9367771, Validation MAE: 5.9061707, Test MAE: 4.5618533\n",
            "Epoch: 220, LR: 0.001000, Loss: 15.1124926, Validation MAE: 5.8866608, Test MAE: 4.5618533\n",
            "Epoch: 221, LR: 0.001000, Loss: 15.0796671, Validation MAE: 5.8577399, Test MAE: 4.5618533\n",
            "Epoch: 222, LR: 0.001000, Loss: 15.2392454, Validation MAE: 5.9712231, Test MAE: 4.5618533\n",
            "Epoch: 223, LR: 0.001000, Loss: 15.1428041, Validation MAE: 6.1201837, Test MAE: 4.5618533\n",
            "Epoch: 224, LR: 0.001000, Loss: 15.3409863, Validation MAE: 6.0125891, Test MAE: 4.5618533\n",
            "Epoch: 225, LR: 0.001000, Loss: 14.3418455, Validation MAE: 6.0962286, Test MAE: 4.5618533\n",
            "Epoch: 226, LR: 0.001000, Loss: 13.5796814, Validation MAE: 6.1930072, Test MAE: 4.5618533\n",
            "Epoch: 227, LR: 0.001000, Loss: 13.7891798, Validation MAE: 6.0150330, Test MAE: 4.5618533\n",
            "Epoch: 228, LR: 0.001000, Loss: 13.7002506, Validation MAE: 5.9750220, Test MAE: 4.5618533\n",
            "Epoch: 229, LR: 0.001000, Loss: 13.7909336, Validation MAE: 6.0333850, Test MAE: 4.5618533\n",
            "Epoch: 230, LR: 0.001000, Loss: 13.3813858, Validation MAE: 6.0940881, Test MAE: 4.5618533\n",
            "Epoch: 231, LR: 0.001000, Loss: 13.0486536, Validation MAE: 5.9912213, Test MAE: 4.5618533\n",
            "Epoch: 232, LR: 0.001000, Loss: 12.7255907, Validation MAE: 6.0054883, Test MAE: 4.5618533\n",
            "Epoch: 233, LR: 0.001000, Loss: 12.8507729, Validation MAE: 6.1930060, Test MAE: 4.5618533\n",
            "Epoch: 234, LR: 0.001000, Loss: 12.8182182, Validation MAE: 6.1444940, Test MAE: 4.5618533\n",
            "Epoch: 235, LR: 0.001000, Loss: 12.5445585, Validation MAE: 5.9658435, Test MAE: 4.5618533\n",
            "Epoch: 236, LR: 0.001000, Loss: 12.3716917, Validation MAE: 5.9091260, Test MAE: 4.5618533\n",
            "Epoch: 237, LR: 0.001000, Loss: 12.3469095, Validation MAE: 5.9377869, Test MAE: 4.5618533\n",
            "Epoch: 238, LR: 0.001000, Loss: 12.2595663, Validation MAE: 5.9328723, Test MAE: 4.5618533\n",
            "Epoch: 239, LR: 0.001000, Loss: 12.1413546, Validation MAE: 5.9146069, Test MAE: 4.5618533\n",
            "Epoch: 240, LR: 0.001000, Loss: 12.1129160, Validation MAE: 5.9971582, Test MAE: 4.5618533\n",
            "Epoch: 241, LR: 0.001000, Loss: 11.9682846, Validation MAE: 6.1022284, Test MAE: 4.5618533\n",
            "Epoch: 242, LR: 0.001000, Loss: 11.8926144, Validation MAE: 6.0609827, Test MAE: 4.5618533\n",
            "Epoch: 243, LR: 0.001000, Loss: 11.7240725, Validation MAE: 6.0287231, Test MAE: 4.5618533\n",
            "Epoch: 244, LR: 0.001000, Loss: 11.7718811, Validation MAE: 6.1065015, Test MAE: 4.5618533\n",
            "Epoch: 245, LR: 0.001000, Loss: 11.6215506, Validation MAE: 6.1130823, Test MAE: 4.5618533\n",
            "Epoch: 246, LR: 0.001000, Loss: 11.5148230, Validation MAE: 6.0331995, Test MAE: 4.5618533\n",
            "Epoch: 247, LR: 0.001000, Loss: 11.4904881, Validation MAE: 6.0442725, Test MAE: 4.5618533\n",
            "Epoch: 248, LR: 0.001000, Loss: 11.3633852, Validation MAE: 6.0729095, Test MAE: 4.5618533\n",
            "Epoch: 249, LR: 0.001000, Loss: 11.3600855, Validation MAE: 6.0010907, Test MAE: 4.5618533\n",
            "Epoch: 250, LR: 0.001000, Loss: 11.2610073, Validation MAE: 6.0125195, Test MAE: 4.5618533\n",
            "Epoch: 251, LR: 0.001000, Loss: 11.2039738, Validation MAE: 6.0892670, Test MAE: 4.5618533\n",
            "Epoch: 252, LR: 0.001000, Loss: 11.1741505, Validation MAE: 6.0588879, Test MAE: 4.5618533\n",
            "Epoch: 253, LR: 0.001000, Loss: 11.0747929, Validation MAE: 6.0375397, Test MAE: 4.5618533\n",
            "Epoch: 254, LR: 0.001000, Loss: 11.0484495, Validation MAE: 6.0943103, Test MAE: 4.5618533\n",
            "Epoch: 255, LR: 0.001000, Loss: 10.9851942, Validation MAE: 6.0828381, Test MAE: 4.5618533\n",
            "Epoch: 256, LR: 0.001000, Loss: 10.9159327, Validation MAE: 6.0526697, Test MAE: 4.5618533\n",
            "Epoch: 257, LR: 0.001000, Loss: 10.8705025, Validation MAE: 6.1133905, Test MAE: 4.5618533\n",
            "Epoch: 258, LR: 0.001000, Loss: 10.8014011, Validation MAE: 6.1260608, Test MAE: 4.5618533\n",
            "Epoch: 259, LR: 0.001000, Loss: 10.7448397, Validation MAE: 6.0835730, Test MAE: 4.5618533\n",
            "Epoch: 260, LR: 0.001000, Loss: 10.7076597, Validation MAE: 6.1450690, Test MAE: 4.5618533\n",
            "Epoch: 261, LR: 0.001000, Loss: 10.6392117, Validation MAE: 6.1407642, Test MAE: 4.5618533\n",
            "Epoch: 262, LR: 0.001000, Loss: 10.5674572, Validation MAE: 6.1173566, Test MAE: 4.5618533\n",
            "Epoch: 263, LR: 0.001000, Loss: 10.5245886, Validation MAE: 6.1616461, Test MAE: 4.5618533\n",
            "Epoch: 264, LR: 0.001000, Loss: 10.5091429, Validation MAE: 6.0287854, Test MAE: 4.5618533\n",
            "Epoch: 265, LR: 0.001000, Loss: 10.6097603, Validation MAE: 6.1775635, Test MAE: 4.5618533\n",
            "Epoch: 266, LR: 0.001000, Loss: 10.4989433, Validation MAE: 6.1662061, Test MAE: 4.5618533\n",
            "Epoch: 267, LR: 0.001000, Loss: 10.3122683, Validation MAE: 6.1163153, Test MAE: 4.5618533\n",
            "Epoch: 268, LR: 0.001000, Loss: 10.3606386, Validation MAE: 6.2211755, Test MAE: 4.5618533\n",
            "Epoch: 269, LR: 0.001000, Loss: 10.2288122, Validation MAE: 6.1427600, Test MAE: 4.5618533\n",
            "Epoch: 270, LR: 0.001000, Loss: 10.1301689, Validation MAE: 6.0693372, Test MAE: 4.5618533\n",
            "Epoch: 271, LR: 0.001000, Loss: 10.1222305, Validation MAE: 6.2301477, Test MAE: 4.5618533\n",
            "Epoch: 272, LR: 0.001000, Loss: 10.1561966, Validation MAE: 5.9663953, Test MAE: 4.5618533\n",
            "Epoch: 273, LR: 0.001000, Loss: 10.7661743, Validation MAE: 6.3122461, Test MAE: 4.5618533\n",
            "Epoch: 274, LR: 0.001000, Loss: 10.3572941, Validation MAE: 6.2812463, Test MAE: 4.5618533\n",
            "Epoch: 275, LR: 0.001000, Loss: 10.1100473, Validation MAE: 6.0526263, Test MAE: 4.5618533\n",
            "Epoch: 276, LR: 0.001000, Loss: 10.2981377, Validation MAE: 6.1917615, Test MAE: 4.5618533\n",
            "Epoch: 277, LR: 0.001000, Loss: 9.8245659, Validation MAE: 6.1748682, Test MAE: 4.5618533\n",
            "Epoch: 278, LR: 0.001000, Loss: 9.9836998, Validation MAE: 5.9653961, Test MAE: 4.5618533\n",
            "Epoch: 279, LR: 0.001000, Loss: 10.1478519, Validation MAE: 6.2268842, Test MAE: 4.5618533\n",
            "Epoch: 280, LR: 0.001000, Loss: 9.7305326, Validation MAE: 6.3128186, Test MAE: 4.5618533\n",
            "Epoch: 281, LR: 0.001000, Loss: 9.7704735, Validation MAE: 5.9800494, Test MAE: 4.5618533\n",
            "Epoch: 282, LR: 0.001000, Loss: 10.3821497, Validation MAE: 6.1454126, Test MAE: 4.5618533\n",
            "Epoch: 283, LR: 0.001000, Loss: 9.8563242, Validation MAE: 6.2196667, Test MAE: 4.5618533\n",
            "Epoch: 284, LR: 0.001000, Loss: 9.6530104, Validation MAE: 6.0652832, Test MAE: 4.5618533\n",
            "Epoch: 285, LR: 0.001000, Loss: 9.9061947, Validation MAE: 6.2456934, Test MAE: 4.5618533\n",
            "Epoch: 286, LR: 0.001000, Loss: 9.3571091, Validation MAE: 6.4167438, Test MAE: 4.5618533\n",
            "Epoch: 287, LR: 0.001000, Loss: 9.9765234, Validation MAE: 5.8610632, Test MAE: 4.5618533\n",
            "Epoch: 288, LR: 0.001000, Loss: 12.3979721, Validation MAE: 6.1810889, Test MAE: 4.5618533\n",
            "Epoch: 289, LR: 0.001000, Loss: 9.2297993, Validation MAE: 6.9501086, Test MAE: 4.5618533\n",
            "Epoch: 290, LR: 0.001000, Loss: 13.1605234, Validation MAE: 5.8564496, Test MAE: 4.5618533\n",
            "Epoch: 291, LR: 0.001000, Loss: 19.8965836, Validation MAE: 5.6570313, Test MAE: 4.5618533\n",
            "Epoch: 292, LR: 0.001000, Loss: 13.7671824, Validation MAE: 7.2589423, Test MAE: 4.5618533\n",
            "Epoch: 293, LR: 0.001000, Loss: 15.7030544, Validation MAE: 6.3019995, Test MAE: 4.5618533\n",
            "Epoch: 294, LR: 0.001000, Loss: 11.7393007, Validation MAE: 5.7285217, Test MAE: 4.5618533\n",
            "Epoch: 295, LR: 0.001000, Loss: 11.9619637, Validation MAE: 5.5779004, Test MAE: 4.5618533\n",
            "Epoch: 296, LR: 0.001000, Loss: 13.8663282, Validation MAE: 5.7264014, Test MAE: 4.5618533\n",
            "Epoch: 297, LR: 0.001000, Loss: 11.7339554, Validation MAE: 5.8729858, Test MAE: 4.5618533\n",
            "Epoch: 298, LR: 0.001000, Loss: 11.2685928, Validation MAE: 5.8385736, Test MAE: 4.5618533\n",
            "Epoch: 299, LR: 0.001000, Loss: 11.4674301, Validation MAE: 5.6299951, Test MAE: 4.5618533\n",
            "Epoch: 300, LR: 0.001000, Loss: 10.4034081, Validation MAE: 5.6555029, Test MAE: 4.5618533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNeYtO3LuyK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02f29031-3848-433c-b2e4-55e79dc9cbc1"
      },
      "source": [
        "test_error = test(test_loader)\n",
        "test_error"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.859552307128906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}